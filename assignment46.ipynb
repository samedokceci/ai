{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBM 409 - Assignment 4: Bird Species Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Data Loading, Preprocessing, and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.1: Imports and Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions for in-memory storage: 128x128 (BGR)\n",
      "Number of classes: 25\n",
      "Training directory: Birds_25/train\n",
      "Validation directory (original): Birds_25/valid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Setup: Imports and Global Parameters\n",
    "import os\n",
    "import cv2 # OpenCV for image manipulation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# tensorflow.keras.utils.to_categorical for one-hot encoding, can be added later if needed for NNs\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE # For t-SNE visualization\n",
    "from sklearn.preprocessing import StandardScaler # For t-SNE and feature scaling\n",
    "import time # For retrying image reads\n",
    "from PIL import Image # For robust image opening and format checks\n",
    "\n",
    "# --- USER CONFIGURABLE PARAMETERS ---\n",
    "# !!! IMPORTANT: SET THIS TO YOUR DATASET PATH !!!\n",
    "DATASET_BASE_DIR = 'Birds_25'  # Path to your 'Birds_25' directory\n",
    "\n",
    "# Image dimensions for resizing and storing in memory (BGR format)\n",
    "IMG_WIDTH = 128 #\n",
    "IMG_HEIGHT = 128 #\n",
    "IMG_CHANNELS = 3 # Images will be stored as BGR\n",
    "\n",
    "NUM_CLASSES = 25 # As per the assignment\n",
    "# --- END USER CONFIGURABLE PARAMETERS ---\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATASET_BASE_DIR, 'train') #\n",
    "VALID_DIR = os.path.join(DATASET_BASE_DIR, 'valid') #\n",
    "\n",
    "print(f\"Image dimensions for in-memory storage: {IMG_WIDTH}x{IMG_HEIGHT} (BGR)\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Training directory: {TRAIN_DIR}\")\n",
    "print(f\"Validation directory (original): {VALID_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.2: Discover Species and Collect Initial Image Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 species. First 5: ['Asian-Green-Bee-Eater', 'Brown-Headed-Barbet', 'Cattle-Egret', 'Common-Kingfisher', 'Common-Myna']...\n",
      "\n",
      "Total original training image paths collected: 30000\n",
      "Total original validation image paths collected: 7500\n"
     ]
    }
   ],
   "source": [
    "species_list = []\n",
    "if os.path.exists(TRAIN_DIR):\n",
    "    species_list = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]) #\n",
    "else:\n",
    "    print(f\"ERROR: Training directory not found at '{TRAIN_DIR}'. Please check DATASET_BASE_DIR.\")\n",
    "    raise FileNotFoundError(f\"Training directory not found: {TRAIN_DIR}\")\n",
    "\n",
    "if not species_list:\n",
    "    print(\"ERROR: Species list is empty. Ensure dataset is structured correctly.\")\n",
    "else:\n",
    "    print(f\"Found {len(species_list)} species. First 5: {species_list[:5]}...\") #\n",
    "    if len(species_list) != NUM_CLASSES:\n",
    "        print(f\"Warning: Discovered {len(species_list)} species, but NUM_CLASSES is set to {NUM_CLASSES}. Will use discovered count: {len(species_list)}\")\n",
    "        NUM_CLASSES = len(species_list)\n",
    "\n",
    "all_original_train_paths = [] #\n",
    "all_original_train_labels_str = [] #\n",
    "all_original_valid_paths = [] #\n",
    "all_original_valid_labels_str = [] #\n",
    "\n",
    "for species_name in species_list:\n",
    "    species_train_dir = os.path.join(TRAIN_DIR, species_name) #\n",
    "    if os.path.isdir(species_train_dir):\n",
    "        for img_file in os.listdir(species_train_dir): #\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')): # Added more common extensions\n",
    "                all_original_train_paths.append(os.path.join(species_train_dir, img_file)) #\n",
    "                all_original_train_labels_str.append(species_name) #\n",
    "\n",
    "    species_valid_dir = os.path.join(VALID_DIR, species_name) #\n",
    "    if os.path.isdir(species_valid_dir):\n",
    "        for img_file in os.listdir(species_valid_dir): #\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')): #\n",
    "                all_original_valid_paths.append(os.path.join(species_valid_dir, img_file)) #\n",
    "                all_original_valid_labels_str.append(species_name) #\n",
    "\n",
    "print(f\"\\nTotal original training image paths collected: {len(all_original_train_paths)}\") #\n",
    "print(f\"Total original validation image paths collected: {len(all_original_valid_paths)}\") #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.3: Encode Labels and Prepare 80-10-10 Split Image Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label mapping (numerical_label: species_name):\n",
      "0: Asian-Green-Bee-Eater\n",
      "1: Brown-Headed-Barbet\n",
      "2: Cattle-Egret\n",
      "3: Common-Kingfisher\n",
      "4: Common-Myna\n",
      "...\n",
      "\n",
      "--- Dataset Split Path Counts (Targeting 400 Train, 80 Test, 80 Val per class) ---\n",
      "Actual training image paths collected: 10000\n",
      "Actual test image paths collected: 2000\n",
      "Actual validation image paths collected: 2000\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# This step prepares the lists of paths and numerically encoded labels for each dataset split.\n",
    "# %% Step 2 Code\n",
    "if not all_original_train_labels_str:\n",
    "    print(\"ERROR: No training labels found from Step 1. Cannot proceed with label encoding.\")\n",
    "    # Handle error or ensure Step 1 ran correctly and found images.\n",
    "    label_encoder = LabelEncoder() # Initialize to prevent later errors, but it won't be fit.\n",
    "    label_mapping = {}\n",
    "    all_original_train_labels_encoded = np.array([])\n",
    "    all_original_valid_labels_encoded = np.array([])\n",
    "else:\n",
    "    label_encoder = LabelEncoder() #\n",
    "    all_original_train_labels_encoded = label_encoder.fit_transform(all_original_train_labels_str) #\n",
    "    if all_original_valid_labels_str: # Only transform if validation labels exist\n",
    "         all_original_valid_labels_encoded = label_encoder.transform(all_original_valid_labels_str) #\n",
    "    else:\n",
    "        all_original_valid_labels_encoded = np.array([], dtype=int) # Ensure it's an empty array of appropriate type\n",
    "        print(\"Warning: No original validation labels found to encode.\")\n",
    "\n",
    "    label_mapping = {i: label for i, label in enumerate(label_encoder.classes_)} #\n",
    "    print(\"\\nLabel mapping (numerical_label: species_name):\") #\n",
    "    for i in range(min(5, len(label_mapping))): # Print first 5\n",
    "        print(f\"{i}: {label_mapping[i]}\")\n",
    "    if len(label_mapping) > 5: print(\"...\") #\n",
    "    \n",
    "    # Update NUM_CLASSES if label_encoder found a different number of classes than initially set\n",
    "    if len(label_encoder.classes_) != NUM_CLASSES and len(label_encoder.classes_) > 0:\n",
    "        print(f\"Warning: Number of classes from LabelEncoder ({len(label_encoder.classes_)}) differs from NUM_CLASSES ({NUM_CLASSES}). Updating NUM_CLASSES to {len(label_encoder.classes_)}.\")\n",
    "        NUM_CLASSES = len(label_encoder.classes_)\n",
    "    elif len(label_encoder.classes_) == 0 :\n",
    "        print(\"ERROR: LabelEncoder found 0 classes. Dataset might be empty or incorrectly structured.\")\n",
    "        NUM_CLASSES = 0\n",
    "\n",
    "# --- DEĞİŞİKLİKLER BURADA BAŞLIYOR ---\n",
    "# Define the number of samples per class for each set\n",
    "SAMPLES_PER_CLASS_TRAIN = 400\n",
    "SAMPLES_PER_CLASS_TEST = 80\n",
    "SAMPLES_PER_CLASS_VALID = 80\n",
    "\n",
    "# Training set paths and labels\n",
    "X_train_paths_temp = []\n",
    "y_train_labels_encoded_list_temp = []\n",
    "original_train_paths_np = np.array(all_original_train_paths)\n",
    "original_train_labels_np = np.array(all_original_train_labels_encoded)\n",
    "\n",
    "for class_idx in range(NUM_CLASSES): #\n",
    "    class_paths = original_train_paths_np[original_train_labels_np == class_idx]\n",
    "    if len(class_paths) == 0:\n",
    "        print(f\"Warning: No original training images found for class index {class_idx} ({label_mapping.get(class_idx, 'Unknown')}).\")\n",
    "        continue\n",
    "    \n",
    "    random.shuffle(class_paths) # Shuffle paths for this class\n",
    "    \n",
    "    selected_train_paths = class_paths[:SAMPLES_PER_CLASS_TRAIN]\n",
    "    X_train_paths_temp.extend(selected_train_paths)\n",
    "    y_train_labels_encoded_list_temp.extend([class_idx] * len(selected_train_paths))\n",
    "    if len(selected_train_paths) < SAMPLES_PER_CLASS_TRAIN:\n",
    "        print(f\"Warning: For training class {label_mapping.get(class_idx, 'Unknown')}, only {len(selected_train_paths)} samples found (requested {SAMPLES_PER_CLASS_TRAIN}).\")\n",
    "\n",
    "X_train_paths = X_train_paths_temp\n",
    "y_train_labels_encoded_np = np.array(y_train_labels_encoded_list_temp)\n",
    "\n",
    "\n",
    "# Validation and Test set paths and labels\n",
    "X_val_paths_temp = []\n",
    "y_val_labels_encoded_list_temp = []\n",
    "X_test_paths_temp = []\n",
    "y_test_labels_encoded_list_temp = []\n",
    "\n",
    "if all_original_valid_paths: # Proceed only if there are validation paths\n",
    "    original_valid_paths_np = np.array(all_original_valid_paths) #\n",
    "    original_valid_labels_np = np.array(all_original_valid_labels_encoded) #\n",
    "\n",
    "    for class_idx in range(NUM_CLASSES): # Iterate up to the effective NUM_CLASSES\n",
    "        class_paths = original_valid_paths_np[original_valid_labels_np == class_idx] #\n",
    "        \n",
    "        if len(class_paths) < SAMPLES_PER_CLASS_TEST + SAMPLES_PER_CLASS_VALID:\n",
    "            print(f\"Warning: Not enough original validation images for class {label_mapping.get(class_idx, 'Unknown')} to create test ({SAMPLES_PER_CLASS_TEST}) and validation ({SAMPLES_PER_CLASS_VALID}) sets. Found {len(class_paths)}.\")\n",
    "            # Adjust if needed, e.g., by taking fewer or splitting what's available\n",
    "            # For simplicity here, we'll take what we can, prioritizing test then validation\n",
    "            random.shuffle(class_paths) #\n",
    "            current_class_test_paths = class_paths[:SAMPLES_PER_CLASS_TEST]\n",
    "            current_class_val_paths = class_paths[SAMPLES_PER_CLASS_TEST : SAMPLES_PER_CLASS_TEST + SAMPLES_PER_CLASS_VALID]\n",
    "            \n",
    "            X_test_paths_temp.extend(current_class_test_paths)\n",
    "            y_test_labels_encoded_list_temp.extend([class_idx] * len(current_class_test_paths))\n",
    "            \n",
    "            X_val_paths_temp.extend(current_class_val_paths)\n",
    "            y_val_labels_encoded_list_temp.extend([class_idx] * len(current_class_val_paths))\n",
    "            continue\n",
    "\n",
    "        random.shuffle(class_paths) # Shuffle paths for this class\n",
    "        \n",
    "        # Assign SAMPLES_PER_CLASS_TEST for test set\n",
    "        selected_test_paths = class_paths[:SAMPLES_PER_CLASS_TEST]\n",
    "        X_test_paths_temp.extend(selected_test_paths)\n",
    "        y_test_labels_encoded_list_temp.extend([class_idx] * len(selected_test_paths))\n",
    "        \n",
    "        # Assign SAMPLES_PER_CLASS_VALID for validation set from the remaining\n",
    "        selected_val_paths = class_paths[SAMPLES_PER_CLASS_TEST : SAMPLES_PER_CLASS_TEST + SAMPLES_PER_CLASS_VALID]\n",
    "        X_val_paths_temp.extend(selected_val_paths)\n",
    "        y_val_labels_encoded_list_temp.extend([class_idx] * len(selected_val_paths))\n",
    "else:\n",
    "    print(\"Warning: 'all_original_valid_paths' is empty. Validation and Test sets will be empty.\") #\n",
    "\n",
    "X_val_paths = X_val_paths_temp\n",
    "y_val_labels_encoded_np = np.array(y_val_labels_encoded_list_temp)\n",
    "X_test_paths = X_test_paths_temp\n",
    "y_test_labels_encoded_np = np.array(y_test_labels_encoded_list_temp)\n",
    "\n",
    "# --- DEĞİŞİKLİKLER BURADA BİTİYOR ---\n",
    "\n",
    "print(f\"\\n--- Dataset Split Path Counts (Targeting {SAMPLES_PER_CLASS_TRAIN} Train, {SAMPLES_PER_CLASS_TEST} Test, {SAMPLES_PER_CLASS_VALID} Val per class) ---\") #\n",
    "print(f\"Actual training image paths collected: {len(X_train_paths)}\") #\n",
    "print(f\"Actual test image paths collected: {len(X_test_paths)}\") #\n",
    "print(f\"Actual validation image paths collected: {len(X_val_paths)}\") #\n",
    "\n",
    "# Convert label lists to NumPy arrays (ensure they are arrays even if empty)\n",
    "y_train_labels_encoded_np = np.array(y_train_labels_encoded_np) #\n",
    "y_val_labels_encoded_np = np.array(y_val_labels_encoded_list_temp) # Use temp list before this line\n",
    "y_test_labels_encoded_np = np.array(y_test_labels_encoded_list_temp)# Use temp list before this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.4: Data Preprocessing (Image Loading, Resizing, and Storage in Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and Resizing All Images (BGR format) into Memory & Filtering Labels ---\n",
      "Attempting to load and resize 10000 images to (128x128)...\n",
      "  Processed 250/10000 image paths for this set.\n",
      "  Processed 500/10000 image paths for this set.\n",
      "  Processed 750/10000 image paths for this set.\n",
      "  Processed 1000/10000 image paths for this set.\n",
      "  Processed 1250/10000 image paths for this set.\n",
      "  Processed 1500/10000 image paths for this set.\n",
      "  Processed 1750/10000 image paths for this set.\n",
      "  Processed 2000/10000 image paths for this set.\n",
      "  Processed 2250/10000 image paths for this set.\n",
      "  Processed 2500/10000 image paths for this set.\n",
      "  Processed 2750/10000 image paths for this set.\n",
      "  Processed 3000/10000 image paths for this set.\n",
      "  Processed 3250/10000 image paths for this set.\n",
      "  Processed 3500/10000 image paths for this set.\n",
      "  Processed 3750/10000 image paths for this set.\n",
      "  Processed 4000/10000 image paths for this set.\n",
      "  Processed 4250/10000 image paths for this set.\n",
      "  Processed 4500/10000 image paths for this set.\n",
      "  Processed 4750/10000 image paths for this set.\n",
      "  Processed 5000/10000 image paths for this set.\n",
      "  Processed 5250/10000 image paths for this set.\n",
      "  Processed 5500/10000 image paths for this set.\n",
      "  Processed 5750/10000 image paths for this set.\n",
      "  Processed 6000/10000 image paths for this set.\n",
      "  Processed 6250/10000 image paths for this set.\n",
      "  Processed 6500/10000 image paths for this set.\n",
      "  Processed 6750/10000 image paths for this set.\n",
      "  Processed 7000/10000 image paths for this set.\n",
      "  Processed 7250/10000 image paths for this set.\n",
      "  Processed 7500/10000 image paths for this set.\n",
      "  Processed 7750/10000 image paths for this set.\n",
      "  Processed 8000/10000 image paths for this set.\n",
      "  Processed 8250/10000 image paths for this set.\n",
      "  Processed 8500/10000 image paths for this set.\n",
      "  Processed 8750/10000 image paths for this set.\n",
      "  Processed 9000/10000 image paths for this set.\n",
      "  Processed 9250/10000 image paths for this set.\n",
      "  Processed 9500/10000 image paths for this set.\n",
      "  Processed 9750/10000 image paths for this set.\n",
      "  Processed 10000/10000 image paths for this set.\n",
      "Finished loading for this set. Successfully loaded/resized 10000 images. Skipped 0 images.\n",
      "Attempting to load and resize 2000 images to (128x128)...\n",
      "  Processed 250/2000 image paths for this set.\n",
      "  Processed 500/2000 image paths for this set.\n",
      "  Processed 750/2000 image paths for this set.\n",
      "  Processed 1000/2000 image paths for this set.\n",
      "  Processed 1250/2000 image paths for this set.\n",
      "  Processed 1500/2000 image paths for this set.\n",
      "  Processed 1750/2000 image paths for this set.\n",
      "  Processed 2000/2000 image paths for this set.\n",
      "Finished loading for this set. Successfully loaded/resized 2000 images. Skipped 0 images.\n",
      "Attempting to load and resize 2000 images to (128x128)...\n",
      "  Processed 250/2000 image paths for this set.\n",
      "  Processed 500/2000 image paths for this set.\n",
      "  Processed 750/2000 image paths for this set.\n",
      "  Processed 1000/2000 image paths for this set.\n",
      "  Processed 1250/2000 image paths for this set.\n",
      "  Processed 1500/2000 image paths for this set.\n",
      "  Processed 1750/2000 image paths for this set.\n",
      "  Processed 2000/2000 image paths for this set.\n",
      "Finished loading for this set. Successfully loaded/resized 2000 images. Skipped 0 images.\n",
      "\n",
      "--- Final Data Shapes After Loading Images into Memory ---\n",
      "X_train_images_bgr shape: (10000, 128, 128, 3), y_train_final shape: (10000,)\n",
      "X_val_images_bgr shape: (2000, 128, 128, 3), y_val_final shape: (2000,)\n",
      "X_test_images_bgr shape: (2000, 128, 128, 3), y_test_final shape: (2000,)\n",
      "Effective NUM_CLASSES for reports: 25\n",
      "Target names for reports (first 5 if available): [np.str_('Asian-Green-Bee-Eater'), np.str_('Brown-Headed-Barbet'), np.str_('Cattle-Egret'), np.str_('Common-Kingfisher'), np.str_('Common-Myna')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: Efficient Image Loading, Resizing, and Storage (BGR format in Memory)\n",
    "# This step reads all images from the split paths ONCE, resizes them, \n",
    "# and stores them in memory as BGR NumPy arrays. \n",
    "# It also filters labels for images that couldn't be loaded/processed robustly.\n",
    "# Normalization (e.g., to [0,1]) will be applied later if a specific model requires it.\n",
    "# For traditional feature extractors (Part 1), we'll often use the 0-255 BGR or Grayscale images derived from these.\n",
    "\n",
    "# %% Step 3 Code\n",
    "print(\"--- Loading and Resizing All Images (BGR format) into Memory & Filtering Labels ---\")\n",
    "\n",
    "def load_resize_and_filter_bgr_efficiently(image_paths, original_labels_np, target_width, target_height, max_retries=3, retry_delay_seconds=1):\n",
    "    \"\"\"\n",
    "    Loads images from paths, resizes to target_width x target_height, stores as BGR.\n",
    "    Retries reading an image if it fails, up to max_retries using PIL for robustness.\n",
    "    Filters out images that cannot be loaded/processed and their corresponding labels.\n",
    "    Returns NumPy arrays of loaded BGR images, filtered labels, and successfully loaded paths.\n",
    "    \"\"\"\n",
    "    loaded_images_bgr_list = []\n",
    "    filtered_labels_list = []\n",
    "    successfully_loaded_paths_list = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    if not image_paths: # Handle empty image_paths list\n",
    "        print(\"Warning: Input image_paths list is empty for efficient loading.\")\n",
    "        # Return empty arrays with appropriate shapes if possible, or just empty arrays\n",
    "        return np.empty((0, target_height, target_width, IMG_CHANNELS), dtype=np.uint8), \\\n",
    "               np.array([], dtype=original_labels_np.dtype if original_labels_np.size > 0 else int), \\\n",
    "               []\n",
    "\n",
    "    total_paths = len(image_paths)\n",
    "    print(f\"Attempting to load and resize {total_paths} images to ({target_width}x{target_height})...\")\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img_bgr = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                pil_img = Image.open(img_path)\n",
    "                pil_img_rgb = pil_img.convert('RGB') \n",
    "                img_bgr = cv2.cvtColor(np.array(pil_img_rgb), cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                if img_bgr is not None:\n",
    "                    break \n",
    "            except FileNotFoundError:\n",
    "                print(f\"ERROR (Attempt {attempt+1}/{max_retries}): File not found {img_path}. Skipping this image.\")\n",
    "                img_bgr = None \n",
    "                break \n",
    "            except Exception as e_read:\n",
    "                print(f\"Warning (Attempt {attempt+1}/{max_retries}): Error reading/converting image {img_path}: {e_read}. Retrying in {retry_delay_seconds}s...\")\n",
    "                time.sleep(retry_delay_seconds)\n",
    "        \n",
    "        if img_bgr is None:\n",
    "            print(f\"ERROR: Failed to load/convert image {img_path} after {max_retries} attempts, skipping.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Ensure image has 3 channels after conversion\n",
    "            if len(img_bgr.shape) != 3 or img_bgr.shape[2] != 3:\n",
    "                print(f\"Warning: Image {img_path} does not have 3 channels after conversion (shape: {img_bgr.shape}), attempting to force BGR.\")\n",
    "                if len(img_bgr.shape) == 2: \n",
    "                    img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_GRAY2BGR)\n",
    "                elif img_bgr.shape[2] == 1: \n",
    "                     img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_GRAY2BGR)\n",
    "                elif img_bgr.shape[2] == 4: \n",
    "                    img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_BGRA2BGR)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported number of channels: {img_bgr.shape[2]}\")\n",
    "\n",
    "            img_bgr_resized = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "            loaded_images_bgr_list.append(img_bgr_resized)\n",
    "            filtered_labels_list.append(original_labels_np[i])\n",
    "            successfully_loaded_paths_list.append(img_path)\n",
    "        except Exception as e_proc:\n",
    "            print(f\"Error resizing/processing image {img_path} (shape: {img_bgr.shape if img_bgr is not None else 'None'}, dtype: {img_bgr.dtype if img_bgr is not None else 'None'}): {e_proc}, skipping.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        if (i + 1) % 250 == 0 or (i + 1) == total_paths: \n",
    "            print(f\"  Processed {i+1}/{total_paths} image paths for this set.\")\n",
    "            \n",
    "    print(f\"Finished loading for this set. Successfully loaded/resized {len(loaded_images_bgr_list)} images. Skipped {skipped_count} images.\")\n",
    "    \n",
    "    # Convert lists to NumPy arrays, ensuring correct dtype and shape for empty lists\n",
    "    final_images_array = np.array(loaded_images_bgr_list, dtype=np.uint8) if loaded_images_bgr_list else np.empty((0, target_height, target_width, IMG_CHANNELS), dtype=np.uint8)\n",
    "    final_labels_array = np.array(filtered_labels_list, dtype=original_labels_np.dtype if original_labels_np.size > 0 else int) if filtered_labels_list else np.array([], dtype=original_labels_np.dtype if original_labels_np.size > 0 else int)\n",
    "    \n",
    "    return final_images_array, final_labels_array, successfully_loaded_paths_list\n",
    "\n",
    "# --- Load all images into memory. These will be used by subsequent parts. ---\n",
    "# The *_final variables will hold the actual BGR image data (0-255 range) and their filtered labels.\n",
    "# X_train_paths etc. are from Step 2 Code cell\n",
    "\n",
    "if 'X_train_paths' not in globals() or not X_train_paths:\n",
    "    print(\"ERROR: X_train_paths is not defined or empty. Please run Step 1 and Step 2 first.\")\n",
    "    # Initialize to prevent errors if subsequent cells are run accidentally\n",
    "    X_train_images_bgr, y_train_final, X_train_paths_final = np.array([]), np.array([]), []\n",
    "    X_val_images_bgr, y_val_final, X_val_paths_final = np.array([]), np.array([]), []\n",
    "    X_test_images_bgr, y_test_final, X_test_paths_final = np.array([]), np.array([]), []\n",
    "else:\n",
    "    X_train_images_bgr, y_train_final, X_train_paths_final = load_resize_and_filter_bgr_efficiently(X_train_paths, y_train_labels_encoded_np, IMG_WIDTH, IMG_HEIGHT)\n",
    "    X_val_images_bgr, y_val_final, X_val_paths_final = load_resize_and_filter_bgr_efficiently(X_val_paths, y_val_labels_encoded_np, IMG_WIDTH, IMG_HEIGHT)\n",
    "    X_test_images_bgr, y_test_final, X_test_paths_final = load_resize_and_filter_bgr_efficiently(X_test_paths, y_test_labels_encoded_np, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "print(\"\\n--- Final Data Shapes After Loading Images into Memory ---\")\n",
    "print(f\"X_train_images_bgr shape: {X_train_images_bgr.shape}, y_train_final shape: {y_train_final.shape}\")\n",
    "print(f\"X_val_images_bgr shape: {X_val_images_bgr.shape}, y_val_final shape: {y_val_final.shape}\")\n",
    "print(f\"X_test_images_bgr shape: {X_test_images_bgr.shape}, y_test_final shape: {y_test_final.shape}\")\n",
    "\n",
    "# Update NUM_CLASSES and target_names_part1 based on actual unique labels found AFTER filtering\n",
    "# This is crucial if some classes were entirely skipped due to loading errors.\n",
    "if y_train_final.size > 0:\n",
    "    # Concatenate all filtered labels to find the true set of classes present in the loaded data\n",
    "    all_loaded_labels_list = []\n",
    "    if y_train_final.size > 0: all_loaded_labels_list.append(y_train_final)\n",
    "    if y_val_final.size > 0: all_loaded_labels_list.append(y_val_final)\n",
    "    if y_test_final.size > 0: all_loaded_labels_list.append(y_test_final)\n",
    "    \n",
    "    if all_loaded_labels_list: # If any labels exist after filtering\n",
    "        all_loaded_labels = np.concatenate(all_loaded_labels_list, axis=0)\n",
    "        unique_loaded_labels = np.unique(all_loaded_labels)\n",
    "        actual_num_classes_loaded = len(unique_loaded_labels)\n",
    "    else: # No labels loaded at all\n",
    "        actual_num_classes_loaded = 0\n",
    "        unique_loaded_labels = np.array([])\n",
    "        print(\"CRITICAL WARNING: No labels loaded into y_train_final, y_val_final, or y_test_final. Dataset might be empty or all images failed to load.\")\n",
    "\n",
    "    if actual_num_classes_loaded != NUM_CLASSES:\n",
    "        print(f\"INFO: Number of unique labels in all loaded data ({actual_num_classes_loaded}) \"\n",
    "              f\"differs from initial NUM_CLASSES ({NUM_CLASSES}). Updating NUM_CLASSES to {actual_num_classes_loaded}.\")\n",
    "        NUM_CLASSES = actual_num_classes_loaded\n",
    "    \n",
    "    if 'label_mapping' in globals():\n",
    "        # Create target names based on labels that are actually present and in label_mapping\n",
    "        target_names_part1 = [label_mapping.get(i, str(i)) for i in sorted(list(unique_loaded_labels))]\n",
    "        if len(target_names_part1) != actual_num_classes_loaded and actual_num_classes_loaded > 0:\n",
    "             print(f\"Warning: Mismatch in target_names_part1 generation ({len(target_names_part1)}) and actual_num_classes_loaded ({actual_num_classes_loaded}). Some labels might not be in label_mapping. Using sorted unique labels as strings for missing ones.\")\n",
    "             # This line ensures target_names_part1 has the correct length, using string of label if not in mapping\n",
    "             target_names_part1 = [label_mapping.get(i, str(i)) for i in sorted(list(unique_loaded_labels))]\n",
    "    else: # Fallback if label_mapping is not defined\n",
    "        target_names_part1 = [str(i) for i in sorted(list(unique_loaded_labels))]\n",
    "        if actual_num_classes_loaded > 0 : print(\"Warning: label_mapping not found. Using sorted unique numerical labels for classification report target names.\")\n",
    "        else: print(\"Warning: label_mapping not found and no labels loaded to derive target_names.\")\n",
    "\n",
    "    print(f\"Effective NUM_CLASSES for reports: {NUM_CLASSES}\")\n",
    "    print(f\"Target names for reports (first 5 if available): {target_names_part1[:5] if target_names_part1 else 'N/A'}\")\n",
    "\n",
    "else: # Handle case where y_train_final itself is empty (meaning no training images loaded)\n",
    "    print(\"ERROR: y_train_final is empty after loading. Cannot reliably set NUM_CLASSES or target_names_part1. This indicates a major issue with training data loading.\")\n",
    "    NUM_CLASSES = 0 # Set to 0 if no training data, to prevent errors in later cells expecting NUM_CLASSES\n",
    "    target_names_part1 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.5: Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Visualization Functions (Adapted for In-Memory BGR Images)\n",
    "# These functions will now primarily operate on the in-memory BGR image arrays \n",
    "# (`X_train_images_bgr`, etc.) and their corresponding filtered labels (`y_train_final`, etc.).\n",
    "# Normalization to [0,1] and BGR->RGB conversion for display are handled within these functions as needed.\n",
    "\n",
    "# %% Step 4 Code\n",
    "# Keep your existing visualization functions (display_sample_images_from_paths, \n",
    "# plot_class_distribution, show_downscaling_effect_from_path, \n",
    "# display_average_processed_images, plot_color_histograms_for_raw_image, \n",
    "# plot_tsne_visualization_of_processed) from your notebook's \"Step 4 Code\" cell.\n",
    "# I will slightly adapt them below to ensure they primarily use the in-memory BGR arrays.\n",
    "# The original `load_raw_image_from_path` and `apply_model_preprocessing` are less needed now\n",
    "# as images are pre-loaded and pre-resized, but `apply_model_preprocessing` might still be useful\n",
    "# if specific models in later parts need normalized [0,1] RGB input.\n",
    "\n",
    "def display_sample_images_from_memory(image_array_bgr, numeric_labels_list, label_mapping_dict,\n",
    "                                   num_samples_per_class=3, num_classes_to_display=5, title_prefix=\"Sample Loaded\"):\n",
    "    \"\"\"Displays sample images from an in-memory BGR NumPy array.\"\"\"\n",
    "    if image_array_bgr.size == 0 or not numeric_labels_list.size:\n",
    "        print(f\"Image array or labels list is empty for '{title_prefix}' display.\")\n",
    "        return\n",
    "\n",
    "    # Group images by class using their indices\n",
    "    images_by_class_indices = {}\n",
    "    for idx, label_numeric in enumerate(numeric_labels_list):\n",
    "        if label_numeric not in images_by_class_indices:\n",
    "            images_by_class_indices[label_numeric] = []\n",
    "        images_by_class_indices[label_numeric].append(idx)\n",
    "\n",
    "    unique_labels_available = list(images_by_class_indices.keys())\n",
    "    if not unique_labels_available: \n",
    "        print(f\"No unique labels available for '{title_prefix}' display.\")\n",
    "        return\n",
    "\n",
    "    selected_labels_numeric = random.sample(unique_labels_available, min(num_classes_to_display, len(unique_labels_available)))\n",
    "\n",
    "    # Adjust subplot layout based on num_samples_per_class\n",
    "    num_rows = len(selected_labels_numeric)\n",
    "    num_cols = num_samples_per_class\n",
    "    plt.figure(figsize=(3 * num_cols, 3.5 * num_rows)) # Adjusted figsize for potentially long titles\n",
    "    plot_idx = 1\n",
    "    for label_numeric in selected_labels_numeric:\n",
    "        class_name = label_mapping_dict.get(label_numeric, f\"Label {label_numeric}\")\n",
    "        class_image_indices = images_by_class_indices.get(label_numeric, [])\n",
    "        if not class_image_indices: continue \n",
    "        \n",
    "        sample_indices = random.sample(class_image_indices, min(num_samples_per_class, len(class_image_indices)))\n",
    "        \n",
    "        for i, img_idx in enumerate(sample_indices):\n",
    "            if plot_idx > num_rows * num_cols: break # Avoid plotting more than subplots\n",
    "            plt.subplot(num_rows, num_cols, plot_idx)\n",
    "            img_bgr_to_display = image_array_bgr[img_idx]\n",
    "            img_rgb_to_display = cv2.cvtColor(img_bgr_to_display, cv2.COLOR_BGR2RGB) \n",
    "            plt.imshow(img_rgb_to_display)\n",
    "            # Truncate long class names if necessary\n",
    "            display_class_name = (class_name[:20] + '...') if len(class_name) > 23 else class_name\n",
    "            plt.title(f\"{title_prefix}: {display_class_name}\\n({img_rgb_to_display.shape[1]}x{img_rgb_to_display.shape[0]})\", fontsize=9)\n",
    "            plt.axis('off')\n",
    "            plot_idx += 1\n",
    "    plt.suptitle(f\"{title_prefix} Images Per Class (from Memory)\", fontsize=16, y=1.0 if num_rows <=1 else 0.98 + (0.02 * (6-num_rows) if num_rows < 6 else 0)) # Adjust suptitle y\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95]) \n",
    "    plt.show()\n",
    "\n",
    "def plot_class_distribution(y_numeric_list, label_mapping_dict, dataset_name=\"Dataset\"): #\n",
    "    \"\"\"Plots class distribution. y_numeric_list should be the filtered labels.\"\"\"\n",
    "    if not isinstance(y_numeric_list, np.ndarray) or y_numeric_list.size == 0:\n",
    "        print(f\"Label array for {dataset_name} is empty or not a NumPy array.\")\n",
    "        return\n",
    "        \n",
    "    unique_labels, counts = np.unique(y_numeric_list, return_counts=True) #\n",
    "    \n",
    "    # Use actual labels present in the data for class names\n",
    "    class_names = [label_mapping_dict.get(label, f\"Class {label}\") for label in unique_labels] #\n",
    "    \n",
    "    df_counts = pd.DataFrame({'Species': class_names, 'Count': counts}).sort_values('Species') #\n",
    "\n",
    "    plt.figure(figsize=(max(14, len(class_names)*0.5), 8)) # Dynamically adjust width\n",
    "    sns.barplot(x='Species', y='Count', data=df_counts, palette=\"viridis\") #\n",
    "    plt.title(f'Class Distribution in {dataset_name} (Total: {sum(counts)} images after filtering)', fontsize=15) #\n",
    "    plt.xlabel('Bird Species', fontsize=12) #\n",
    "    plt.ylabel('Number of Samples', fontsize=12) #\n",
    "    # Adjust rotation and font size for better readability if many classes\n",
    "    plt.xticks(rotation=60 if len(class_names) > 15 else 45, \n",
    "               ha=\"right\", \n",
    "               fontsize=min(10, 200.0/len(class_names) if len(class_names) > 0 else 10)) #\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7) #\n",
    "    plt.tight_layout() #\n",
    "    plt.show() #\n",
    "\n",
    "def show_downscaling_effect_from_memory_and_path(in_memory_bgr_image_resized, original_image_path, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Shows original image (read from path for true original dimensions) vs. \n",
    "    the resized version stored in memory (and its normalized version for display).\n",
    "    \"\"\"\n",
    "    raw_img_for_display_rgb = None\n",
    "    original_dims_str = \"(Original Dim. Unknown - Path Error)\"\n",
    "    if original_image_path and os.path.exists(original_image_path):\n",
    "        try:\n",
    "            pil_img_orig = Image.open(original_image_path)\n",
    "            raw_img_for_display_rgb = np.array(pil_img_orig.convert('RGB'))\n",
    "            original_dims_str = f\"({raw_img_for_display_rgb.shape[1]}x{raw_img_for_display_rgb.shape[0]})\"\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load original image from path {original_image_path} for downscaling demo: {e}\")\n",
    "            \n",
    "    if in_memory_bgr_image_resized is None or in_memory_bgr_image_resized.size == 0:\n",
    "        print(\"In-memory resized image is not available for downscaling demo.\")\n",
    "        if raw_img_for_display_rgb is None: return\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(raw_img_for_display_rgb)\n",
    "        plt.title(f'Original Image (Failed to compare with in-memory)\\n{original_dims_str}')\n",
    "        plt.axis('off'); plt.show()\n",
    "        return\n",
    "\n",
    "    img_rgb_resized_from_memory = cv2.cvtColor(in_memory_bgr_image_resized, cv2.COLOR_BGR2RGB)\n",
    "    processed_img_for_display_normalized = img_rgb_resized_from_memory.astype('float32') / 255.0\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5)) # Simpler layout\n",
    "    if raw_img_for_display_rgb is not None:\n",
    "        axes[0].imshow(raw_img_for_display_rgb)\n",
    "    else: \n",
    "        axes[0].imshow(img_rgb_resized_from_memory) \n",
    "        original_dims_str = f\"(Displaying In-Memory Resized: {target_width}x{target_height})\"\n",
    "    axes[0].set_title(f'Original-Like Image\\n{original_dims_str}')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(processed_img_for_display_normalized) \n",
    "    axes[1].set_title(f'Stored & Resized ({target_width}x{target_height})\\nDisplayed as RGB Normalized')\n",
    "    axes[1].axis('off')\n",
    "    fig.suptitle(\"Image State: Original-Like vs. Stored & Displayed\", fontsize=14, y=1.0) # Adjusted y for suptitle\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "\n",
    "def display_average_images_from_memory(X_images_bgr, y_numeric_list, label_mapping_dict, num_classes_to_display=5):\n",
    "    \"\"\"Displays average images from an in-memory BGR NumPy array.\"\"\"\n",
    "    if X_images_bgr.size == 0 or not y_numeric_list.size:\n",
    "        print(\"Image array or labels are empty for average image display.\")\n",
    "        return\n",
    "        \n",
    "    unique_labels = np.unique(y_numeric_list)\n",
    "    if not unique_labels.size:\n",
    "        print(\"No unique labels to display average images for.\")\n",
    "        return\n",
    "        \n",
    "    selected_labels = random.sample(list(unique_labels), min(num_classes_to_display, len(unique_labels)))\n",
    "    \n",
    "    num_cols_avg = min(5, len(selected_labels)) # Max 5 images per row\n",
    "    num_rows_avg = (len(selected_labels) - 1) // num_cols_avg + 1\n",
    "    plt.figure(figsize=(3.5 * num_cols_avg, 3.5 * num_rows_avg)) # Slightly larger images\n",
    "\n",
    "    for i, label_numeric in enumerate(selected_labels):\n",
    "        class_images_bgr = X_images_bgr[y_numeric_list == label_numeric]\n",
    "        if class_images_bgr.shape[0] == 0: continue\n",
    "        \n",
    "        average_image_bgr_float = np.mean(class_images_bgr, axis=0)\n",
    "        average_image_bgr_uint8 = np.clip(average_image_bgr_float, 0, 255).astype(np.uint8)\n",
    "        average_image_rgb_display = cv2.cvtColor(average_image_bgr_uint8, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        plt.subplot(num_rows_avg, num_cols_avg, i + 1)\n",
    "        plt.imshow(average_image_rgb_display)\n",
    "        class_name_display = label_mapping_dict.get(label_numeric, str(label_numeric))\n",
    "        class_name_display = (class_name_display[:15] + '...') if len(class_name_display) > 18 else class_name_display\n",
    "        plt.title(f\"Avg: {class_name_display}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Average Images Per Class (from Memory, BGR -> RGB for display)\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "\n",
    "def plot_color_histograms_for_bgr_image(image_bgr, title=\"Color Histogram (BGR channels)\"): #\n",
    "    \"\"\"Plots BGR color histograms for a single BGR image (0-255 range).\"\"\"\n",
    "    if image_bgr is None or image_bgr.size == 0 : \n",
    "        print(f\"Image for histogram ('{title}') is None or empty.\")\n",
    "        return\n",
    "    \n",
    "    if image_bgr.dtype != np.uint8:\n",
    "        print(f\"Warning: Image for histogram ('{title}') is not uint8 (dtype: {image_bgr.dtype}). Clipping and converting.\")\n",
    "        image_bgr = np.clip(image_bgr, 0, 255).astype(np.uint8)\n",
    "\n",
    "    colors, channel_names = (('b', 'g', 'r')), (('Blue', 'Green', 'Red')) \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5)) \n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(\"Image for Histograms\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for channel_idx, color_char in enumerate(colors[0]): \n",
    "        histogram = cv2.calcHist([image_bgr], [channel_idx], None, [256], [0, 256]) #\n",
    "        axes[1].plot(histogram, color=color_char, label=f'{channel_names[0][channel_idx]} channel') #\n",
    "    \n",
    "    axes[1].set_title(title, fontsize=12) # Reduced title fontsize slightly\n",
    "    axes[1].set_xlabel(\"Pixel Intensity (0-255)\") #\n",
    "    axes[1].set_ylabel(\"Number of Pixels\") #\n",
    "    axes[1].legend() #\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.7) #\n",
    "    axes[1].set_xlim([0, 256]) #\n",
    "    fig.suptitle(\"Image and its BGR Color Histograms\", fontsize=14, y=1.0) # Main suptitle\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93]) # Adjust rect for suptitle\n",
    "    plt.show()\n",
    "\n",
    "def plot_tsne_visualization_from_memory(X_images_bgr, y_numeric_list, label_mapping_dict, \n",
    "                                        n_samples_subset=1000, perplexity_val=30.0): # perplexity_val is float\n",
    "    \"\"\"Performs t-SNE on a subset of in-memory BGR images (0-255 range).\"\"\"\n",
    "    if X_images_bgr.size == 0 or not y_numeric_list.size:\n",
    "        print(\"Image array or labels are empty for t-SNE.\")\n",
    "        return\n",
    "        \n",
    "    actual_samples = min(n_samples_subset, X_images_bgr.shape[0])\n",
    "    \n",
    "    # Perplexity must be less than n_samples. scikit-learn default is 30.0.\n",
    "    # It must be > 0. It's recommended to be between 5 and 50.\n",
    "    effective_perplexity = min(float(perplexity_val), float(actual_samples - 1)) \n",
    "    if actual_samples <=1 or effective_perplexity < 1.0 : \n",
    "        print(f\"Subset size {actual_samples} is too small or perplexity {effective_perplexity} is too low. t-SNE requires at least 2 samples and perplexity >= 1. Skipping t-SNE.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nPerforming t-SNE on a subset of {actual_samples} BGR images (from memory)...\")\n",
    "    indices = np.random.choice(X_images_bgr.shape[0], actual_samples, replace=False) #\n",
    "    X_subset_bgr, y_subset = X_images_bgr[indices], y_numeric_list[indices] #\n",
    "    \n",
    "    X_flattened = X_subset_bgr.reshape(actual_samples, -1).astype('float32') # Convert to float for scaler\n",
    "    \n",
    "    scaler = StandardScaler() #\n",
    "    X_scaled = scaler.fit_transform(X_flattened) #\n",
    "    \n",
    "    print(f\"t-SNE input shape: {X_scaled.shape}, perplexity: {effective_perplexity}\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=effective_perplexity, \n",
    "                n_iter=300, init='pca', learning_rate='auto', verbose=0) # Added init='pca', learning_rate='auto' for robustness\n",
    "    X_tsne = tsne.fit_transform(X_scaled) #\n",
    "\n",
    "    plt.figure(figsize=(14, 10)) #\n",
    "    unique_labels_in_subset = np.unique(y_subset) #\n",
    "    \n",
    "    num_unique_labels = len(unique_labels_in_subset)\n",
    "    cmap = plt.cm.get_cmap('turbo', num_unique_labels) if num_unique_labels > 20 else plt.cm.get_cmap('tab20', max(1,num_unique_labels))\n",
    "\n",
    "    for i, label_numeric in enumerate(unique_labels_in_subset): #\n",
    "        class_name = label_mapping_dict.get(label_numeric, str(label_numeric)) #\n",
    "        # Truncate long class names for legend\n",
    "        display_class_name_legend = (class_name[:18] + '...') if len(class_name) > 20 else class_name\n",
    "        \n",
    "        plt.scatter(X_tsne[y_subset == label_numeric, 0], X_tsne[y_subset == label_numeric, 1], #\n",
    "                    label=display_class_name_legend, alpha=0.8, \n",
    "                    color=cmap(i / max(1, num_unique_labels -1 ) if num_unique_labels > 1 else 0 ), # Normalize index for cmap\n",
    "                    s=50) \n",
    "    plt.title(f't-SNE Visualization of {actual_samples} BGR Image Pixel Data (from Memory)', fontsize=15) #\n",
    "    plt.xlabel('t-SNE Component 1'); plt.ylabel('t-SNE Component 2') #\n",
    "    \n",
    "    if num_unique_labels <= 25 and num_unique_labels > 0: # Show legend if not too many classes\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), markerscale=1.0, title=\"Species\", fontsize='small') #\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1]) # Make space for legend\n",
    "    else:\n",
    "        plt.tight_layout() #\n",
    "        if num_unique_labels > 0: print(\"More than 25 classes, legend might be too crowded to display effectively.\")\n",
    "            \n",
    "    plt.grid(True, linestyle=':', alpha=0.5) #\n",
    "    plt.show() #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0.6: Data Visualizations and Train, Test and Valid Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Data Visualizations (Using In-Memory Data)\n",
    "# These calls will now use the pre-loaded and filtered `X_..._images_bgr` and `y_..._final` arrays.\n",
    "\n",
    "# %% Step 5 Code\n",
    "# Ensure the variables X_train_images_bgr, y_train_final (and _val, _test versions) \n",
    "# and label_mapping are available from the \"Efficient Image Loading\" cell (Step 3).\n",
    "\n",
    "# print(\"\\n--- Displaying Sample Loaded Images from Training Set (Memory) ---\") #\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.shape[0] > 0: # Check if array has content\n",
    "#     display_sample_images_from_memory(X_train_images_bgr, y_train_final, label_mapping, num_classes_to_display=5, title_prefix=\"Train Sample\")\n",
    "# else:\n",
    "#     print(\"X_train_images_bgr is empty or not defined. Cannot display sample images.\")\n",
    "\n",
    "# print(\"\\n--- Class Distribution Plots (Using Filtered Labels) ---\") #\n",
    "# if 'y_train_final' in globals() and y_train_final.shape[0] > 0:\n",
    "#     plot_class_distribution(y_train_final, label_mapping, \"Training Set (Filtered)\") #\n",
    "# if 'y_val_final' in globals() and y_val_final.shape[0] > 0:\n",
    "#     plot_class_distribution(y_val_final, label_mapping, \"Validation Set (Filtered)\") #\n",
    "# if 'y_test_final' in globals() and y_test_final.shape[0] > 0:\n",
    "#     plot_class_distribution(y_test_final, label_mapping, \"Test Set (Filtered)\") #\n",
    "\n",
    "# print(\"\\n--- Downscaling Effect Visualization (Using a Sample from Memory) ---\") #\n",
    "# # We need an original path for this to show the *true* original. We stored successfully_loaded_paths.\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.shape[0] > 0 and \\\n",
    "#    'X_train_paths_final' in globals() and X_train_paths_final: # Ensure we have paths for original dimensions\n",
    "#     sample_idx_downscale = random.randint(0, X_train_images_bgr.shape[0] - 1)\n",
    "#     img_bgr_resized_for_downscale_demo = X_train_images_bgr[sample_idx_downscale]\n",
    "#     original_path_for_downscale_demo = X_train_paths_final[sample_idx_downscale] # Use the filtered path\n",
    "#     show_downscaling_effect_from_memory_and_path(img_bgr_resized_for_downscale_demo, original_path_for_downscale_demo, IMG_WIDTH, IMG_HEIGHT) #\n",
    "# else:\n",
    "#     print(\"Cannot show downscaling effect: Training image data or successfully loaded paths are missing.\")\n",
    "\n",
    "# print(\"\\n--- Average Images Per Class (from Memory) ---\") #\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.shape[0] > 0:\n",
    "#     display_average_images_from_memory(X_train_images_bgr, y_train_final, label_mapping, num_classes_to_display=min(NUM_CLASSES if 'NUM_CLASSES' in globals() and NUM_CLASSES > 0 else 5, 5)) #\n",
    "# else:\n",
    "#     print(\"X_train_images_bgr is empty. Cannot display average images.\")\n",
    "\n",
    "# print(\"\\n--- Color Histograms for a Sample Image (from Memory, BGR channels) ---\") #\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.shape[0] > 0:\n",
    "#     sample_idx_hist = random.randint(0, X_train_images_bgr.shape[0] - 1)\n",
    "#     img_bgr_for_hist_demo = X_train_images_bgr[sample_idx_hist]\n",
    "#     plot_color_histograms_for_bgr_image(img_bgr_for_hist_demo, title=\"Sample BGR Color Histogram (from Memory)\") #\n",
    "# else:\n",
    "#     print(\"X_train_images_bgr is empty. Cannot display color histograms.\")\n",
    "    \n",
    "# print(\"\\n--- t-SNE Visualization of BGR Image Pixel Data (from Memory) ---\") #\n",
    "# # For t-SNE on raw pixels, use the BGR images directly.\n",
    "# # It can be slow, so a subset is recommended as in your original code.\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.shape[0] > 0:\n",
    "#     # plot_tsne_visualization_from_memory(X_train_images_bgr, y_train_final, label_mapping, n_samples_subset=min(500, X_train_images_bgr.shape[0]), perplexity_val=30.0) # Ensure perplexity is float and less than n_samples\n",
    "# # else:\n",
    "#     # print(\"X_train_images_bgr is empty. Cannot run t-SNE visualization.\")\n",
    "    \n",
    "# %% [markdown]\n",
    "# --- End of Part 0 (Optimized) ---\n",
    "# The variables X_train_images_bgr, y_train_final, X_val_images_bgr, y_val_final, \n",
    "# X_test_images_bgr, y_test_final, X_train_paths_final (and _val, _test for original path reference)\n",
    "# and target_names_part1 are now ready for Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Classification According to Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Part 1: Classification According to Feature Extraction (HSV, HoG, Gabor - Parallel with MLP)\n",
    "\n",
    "# %%\n",
    "# Önceki importlarınıza ek olarak veya mevcut olanları kontrol ederek:\n",
    "from skimage.feature import hog\n",
    "from skimage import color, filters # Gabor için filters modülü\n",
    "import cv2 # OpenCV zaten import edilmiş olmalı\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "\n",
    "# ML Modelleri ve Pipeline için gerekli importlar\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier # Naive Bayes yerine MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: Visualizing Feature Extraction Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.2.1: Function Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Part 0'dan gelen değişkenler varsayılıyor:\n",
    "# X_train_images_bgr, y_train_final\n",
    "# X_test_images_bgr, y_test_final\n",
    "# target_names_part1 (sınıf isimleri listesi)\n",
    "# IMG_WIDTH, IMG_HEIGHT (örneğin 128, 128)\n",
    "\n",
    "# --- Özellik Çıkarım Fonksiyonları ---\n",
    "# (extract_hsv_histogram_single_image, extract_hog_features_single_image, extract_gabor_features_single_image fonksiyonları\n",
    "# bir önceki yanıttaki gibi burada tanımlı olmalıdır)\n",
    "\n",
    "def extract_hsv_histogram_single_image(image_bgr, h_bins=8, s_bins=4, v_bins=4):\n",
    "    \"\"\"Tek bir BGR resimden HSV renk histogramı özelliklerini çıkarır.\"\"\"\n",
    "    if image_bgr is None:\n",
    "        return None\n",
    "    try:\n",
    "        image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "        hist = cv2.calcHist([image_hsv], [0, 1, 2], None, \n",
    "                            [h_bins, s_bins, v_bins], \n",
    "                            [0, 180, 0, 256, 0, 256]) # Hue için 0-179 aralığı\n",
    "        cv2.normalize(hist, hist) # Normalizasyon\n",
    "        return hist.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting HSV histogram: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_hog_features_single_image(image_bgr):\n",
    "    \"\"\"Tek bir BGR resimden HoG özelliklerini çıkarır.\"\"\"\n",
    "    if image_bgr is None:\n",
    "        return None\n",
    "    try:\n",
    "        image_gray = color.rgb2gray(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "        features = hog(image_gray, pixels_per_cell=(16, 16), \n",
    "                       cells_per_block=(2, 2), orientations=9,\n",
    "                       visualize=False, feature_vector=True, block_norm='L2-Hys')\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting HoG features: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_gabor_features_single_image(image_bgr, num_orientations=8, frequencies=(0.05, 0.25, 0.5), sigmas=(1,3)):\n",
    "    \"\"\"Tek bir BGR resimden Gabor filtresi tepkilerinin ortalama ve std. sapmasını çıkarır.\"\"\"\n",
    "    if image_bgr is None:\n",
    "        return None\n",
    "    try:\n",
    "        image_gray = color.rgb2gray(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "        gabor_features = []\n",
    "        for theta_idx in range(num_orientations):\n",
    "            theta = theta_idx / float(num_orientations) * np.pi\n",
    "            for frequency in frequencies:\n",
    "                for sigma_val in sigmas:\n",
    "                    filt_real, filt_imag = filters.gabor(image_gray, frequency=frequency, theta=theta, sigma_x=sigma_val, sigma_y=sigma_val)\n",
    "                    magnitude = np.sqrt(filt_real**2 + filt_imag**2)\n",
    "                    gabor_features.append(np.mean(magnitude))\n",
    "                    gabor_features.append(np.std(magnitude))\n",
    "        return np.array(gabor_features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting Gabor features: {e}\")\n",
    "        return None\n",
    "\n",
    "# %%\n",
    "# --- ML Modellerini Getiren Fonksiyon (NaiveBayes yerine MLP ile GÜNCELLENDİ) ---\n",
    "def get_ml_models():\n",
    "    models = {\n",
    "        \"SVM\": SVC(kernel='rbf', C=1.0, random_state=42, probability=True, max_iter=1000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        \"LogisticRegression\": LogisticRegression(solver='liblinear', max_iter=200, random_state=42), \n",
    "        \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42, early_stopping=True) # NaiveBayes yerine\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# %%\n",
    "# --- Her bir işlem (thread/process) için ana işleyici fonksiyon ---\n",
    "# process_feature_and_models fonksiyonu bir önceki yanıttaki (Turn 13 veya 14) gibi kalacak.\n",
    "# Sadece get_ml_models() fonksiyonunun güncellenmiş halini kullanacak.\n",
    "# Bu fonksiyonu bir önceki yanıttan kopyalayıp buraya veya bir önceki hücreye ekleyebilirsiniz.\n",
    "# Eğer zaten notebook'unuzda varsa, sadece get_ml_models çağrısının doğru olduğundan emin olun.\n",
    "# (Örnek: Bir önceki yanıttaki gibi process_feature_and_models fonksiyonu)\n",
    "\n",
    "def process_feature_and_models(feature_name, feature_extractor_func,\n",
    "                               X_train_imgs, y_train_labels,\n",
    "                               X_test_imgs, y_test_labels,\n",
    "                               ml_models_dict, target_names):\n",
    "    \"\"\"\n",
    "    Belirli bir özellik çıkarıcıyı kullanarak özellikleri çıkarır,\n",
    "    ardından verilen ML modellerini eğitir ve test eder.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting process for {feature_name} ---\")\n",
    "    \n",
    "    # 1. Özellik Çıkarımı\n",
    "    print(f\"Extracting {feature_name} features for training set...\")\n",
    "    start_fe_time = time.time()\n",
    "    # Özellik çıkarımını doğrudan numpy array üzerinde yapalım\n",
    "    X_train_features_list = [feature_extractor_func(img) for img in X_train_imgs]\n",
    "    \n",
    "    # Başarısız olanları (None dönenleri) ve karşılık gelen etiketleri filtrele\n",
    "    successful_train_indices = [i for i, f in enumerate(X_train_features_list) if f is not None]\n",
    "    if len(successful_train_indices) == 0:\n",
    "        print(f\"ERROR: No training features successfully extracted for {feature_name}. Skipping.\")\n",
    "        return {feature_name: \"Feature extraction failed for all training samples.\"}\n",
    "    X_train_features = np.array([X_train_features_list[i] for i in successful_train_indices])\n",
    "    y_train_labels_filtered = y_train_labels[successful_train_indices]\n",
    "\n",
    "    if X_train_features.size == 0:\n",
    "        print(f\"ERROR: No training features extracted (after filtering None) for {feature_name}. Skipping.\")\n",
    "        return {feature_name: \"Feature extraction resulted in empty training set.\"}\n",
    "\n",
    "    print(f\"Extracting {feature_name} features for test set...\")\n",
    "    X_test_features_list = [feature_extractor_func(img) for img in X_test_imgs]\n",
    "    \n",
    "    successful_test_indices = [i for i, f in enumerate(X_test_features_list) if f is not None]\n",
    "    if len(successful_test_indices) == 0:\n",
    "        print(f\"ERROR: No test features successfully extracted for {feature_name}. Skipping model evaluations for this feature.\")\n",
    "        return {feature_name: \"Feature extraction failed for all test samples.\"}\n",
    "    X_test_features = np.array([X_test_features_list[i] for i in successful_test_indices])\n",
    "    y_test_labels_filtered = y_test_labels[successful_test_indices]\n",
    "    \n",
    "    if X_test_features.size == 0:\n",
    "        print(f\"ERROR: No test features extracted (after filtering None) for {feature_name}. Skipping.\")\n",
    "        return {feature_name: \"Feature extraction resulted in empty test set.\"}\n",
    "\n",
    "    end_fe_time = time.time()\n",
    "    print(f\"{feature_name} feature extraction completed in {end_fe_time - start_fe_time:.2f} seconds.\")\n",
    "    print(f\"Train features shape: {X_train_features.shape}, Test features shape: {X_test_features.shape}\")\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # 2. ML Modellerini Eğitme ve Test Etme\n",
    "    for model_name, model_instance in ml_models_dict.items():\n",
    "        print(f\"\\nTraining {model_name} with {feature_name} features...\")\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('classifier', model_instance)\n",
    "        ])\n",
    "        \n",
    "        start_train_time = time.time()\n",
    "        try:\n",
    "            if X_train_features.shape[1] != X_test_features.shape[1]:\n",
    "                 print(f\"ERROR: Feature dimension mismatch for {feature_name} between train ({X_train_features.shape[1]}) and test ({X_test_features.shape[1]}). Skipping {model_name}.\")\n",
    "                 results[f\"{feature_name}_{model_name}\"] = {\"error\": \"Feature dimension mismatch\"}\n",
    "                 continue\n",
    "\n",
    "            if X_train_features.shape[0] == 0 or y_train_labels_filtered.shape[0] == 0:\n",
    "                print(f\"ERROR: Empty training features or labels for {feature_name}. Skipping {model_name}.\")\n",
    "                results[f\"{feature_name}_{model_name}\"] = {\"error\": \"Empty training data\"}\n",
    "                continue\n",
    "            \n",
    "            if len(np.unique(y_train_labels_filtered)) < 2 :\n",
    "                print(f\"ERROR: Training data for {feature_name} has less than 2 classes. Skipping {model_name}.\")\n",
    "                results[f\"{feature_name}_{model_name}\"] = {\"error\": \"Less than 2 classes in training data\"}\n",
    "                continue\n",
    "\n",
    "\n",
    "            pipeline.fit(X_train_features, y_train_labels_filtered)\n",
    "        except ValueError as e:\n",
    "            print(f\"ERROR training {model_name} with {feature_name}: {e}. Skipping this model.\")\n",
    "            results[f\"{feature_name}_{model_name}\"] = {\"error\": str(e)}\n",
    "            continue\n",
    "        end_train_time = time.time()\n",
    "        print(f\"{model_name} training completed in {end_train_time - start_train_time:.2f} seconds.\")\n",
    "        \n",
    "        # Test seti üzerinde değerlendirme\n",
    "        if X_test_features.shape[0] > 0 and y_test_labels_filtered.shape[0] > 0 :\n",
    "            if len(np.unique(y_test_labels_filtered)) < 2 and len(np.unique(y_test_labels_filtered)) != len(np.unique(y_train_labels_filtered)):\n",
    "                 print(f\"Warning: Test data for {feature_name} has less than 2 classes or different class set than train. Report might be problematic.\")\n",
    "            \n",
    "            y_pred = pipeline.predict(X_test_features)\n",
    "            accuracy = accuracy_score(y_test_labels_filtered, y_pred)\n",
    "            try:\n",
    "                # Sınıflandırma raporu için etiketlerin hem train hem de test setinde olmasını sağlamak gerekebilir\n",
    "                # Eğer target_names verilmiyorsa, sadece mevcut etiketleri kullanır.\n",
    "                # Modelin eğitildiği sınıflarla testteki sınıflar aynı olmalı.\n",
    "                unique_labels_in_test_and_train = sorted(list(set(y_train_labels_filtered) | set(y_test_labels_filtered)))\n",
    "                current_target_names = [target_names[i] for i in unique_labels_in_test_and_train if i < len(target_names)]\n",
    "\n",
    "                report = classification_report(y_test_labels_filtered, y_pred, labels=unique_labels_in_test_and_train, target_names=current_target_names, zero_division=0, output_dict=True)\n",
    "            except ValueError as e: \n",
    "                print(f\"Warning: Could not generate classification report for {model_name} with {feature_name} due to label mismatch or other issues: {e}\")\n",
    "                report = {\"error\": str(e), \"accuracy_manual\": accuracy}\n",
    "\n",
    "\n",
    "            print(f\"\\n{model_name} with {feature_name} - Test Set:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            if \"error\" not in report and 'macro avg' in report:\n",
    "                print(f\"Macro Avg F1-score: {report.get('macro avg', {}).get('f1-score', 'N/A'):.4f}\")\n",
    "            \n",
    "            results[f\"{feature_name}_{model_name}\"] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"classification_report_dict\": report \n",
    "            }\n",
    "        else:\n",
    "            print(f\"Test features for {feature_name} are empty or labels are missing. Skipping evaluation for {model_name}.\")\n",
    "            results[f\"{feature_name}_{model_name}\"] = {\"error\": \"Empty test features or labels\"}\n",
    "            \n",
    "    print(f\"--- Finished process for {feature_name} ---\")\n",
    "    return {feature_name: results}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2: Feature Extraction Algorithm Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # ## Visualizing Feature Extraction Processes Step-by-Step\n",
    "\n",
    "# # %%\n",
    "# # Required libraries (ensure these are imported in your notebook)\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skimage.feature import hog\n",
    "# from skimage import color, exposure, filters # filters for Gabor\n",
    "# import random\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### 1. HSV Color Space: Staged Visualization Function\n",
    "\n",
    "# # %%\n",
    "# def visualize_hsv_stages(image_bgr):\n",
    "#     \"\"\"\n",
    "#     Visualizes the stages of converting a BGR image to HSV.\n",
    "#     \"\"\"\n",
    "#     if image_bgr is None:\n",
    "#         print(\"Input image cannot be None.\")\n",
    "#         return\n",
    "\n",
    "#     # Step 1: Original BGR Image (converted to RGB for Matplotlib)\n",
    "#     image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Step 2: Convert BGR to HSV\n",
    "#     image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#     # Step 3: Split HSV Channels\n",
    "#     h_channel, s_channel, v_channel = cv2.split(image_hsv)\n",
    "\n",
    "#     # Visualization\n",
    "#     fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "#     axs[0, 0].imshow(image_rgb)\n",
    "#     axs[0, 0].set_title('1. Original Image (RGB)')\n",
    "#     axs[0, 0].axis('off')\n",
    "\n",
    "#     axs[0, 1].imshow(image_hsv) # Direct display of HSV can look unusual\n",
    "#     axs[0, 1].set_title('2. HSV Image (Direct Display)')\n",
    "#     axs[0, 1].axis('off')\n",
    "    \n",
    "#     axs[1, 0].imshow(h_channel, cmap='hsv') # 'hsv' colormap for Hue channel\n",
    "#     axs[1, 0].set_title('3a. Hue Channel')\n",
    "#     axs[1, 0].axis('off')\n",
    "\n",
    "#     axs[1, 1].imshow(s_channel, cmap='gray')\n",
    "#     axs[1, 1].set_title('3b. Saturation Channel')\n",
    "#     axs[1, 1].axis('off')\n",
    "    \n",
    "#     # To also display the Value channel, adjust subplot layout (e.g., 2,3 or 1,4)\n",
    "#     # fig_v, ax_v = plt.subplots(1,1, figsize=(5,5))\n",
    "#     # ax_v.imshow(v_channel, cmap='gray')\n",
    "#     # ax_v.set_title('3c. Value Channel')\n",
    "#     # ax_v.axis('off')\n",
    "#     # plt.show()\n",
    "\n",
    "\n",
    "#     plt.suptitle('HSV Conversion Stages', fontsize=16)\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Make space for suptitle\n",
    "#     plt.show()\n",
    "\n",
    "#     print(\"Characteristics of HSV Channels:\")\n",
    "#     print(f\"  Hue (H) channel value range: {np.min(h_channel)} - {np.max(h_channel)}\")\n",
    "#     print(f\"  Saturation (S) channel value range: {np.min(s_channel)} - {np.max(s_channel)}\")\n",
    "#     print(f\"  Value (V) channel value range: {np.min(v_channel)} - {np.max(v_channel)}\")\n",
    "#     print(\"\\nFeatures typically extracted from HSV include:\")\n",
    "#     print(\"  - Histograms of the channels (e.g., 1D H, S, V histograms, or a 3D combined histogram)\")\n",
    "#     print(\"  - Statistical moments like mean, standard deviation of channels\")\n",
    "#     print(\"  - Pixel counts in specific color ranges (after color masking)\")\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### 2. HoG (Histogram of Oriented Gradients): Staged Visualization Function\n",
    "\n",
    "# # %%\n",
    "# def visualize_hog_stages(image_bgr, pixels_per_cell=(16, 16), cells_per_block=(2, 2), orientations=9):\n",
    "#     \"\"\"\n",
    "#     Visualizes the basic stages of HoG feature extraction from a BGR image.\n",
    "#     \"\"\"\n",
    "#     if image_bgr is None:\n",
    "#         print(\"Input image cannot be None.\")\n",
    "#         return\n",
    "\n",
    "#     # Step 1: Original Image and Convert to Grayscale\n",
    "#     image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "#     image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY) # Or use skimage.color.rgb2gray\n",
    "\n",
    "#     # Step 2: Calculate Gradients (HoG does this internally, showing an example)\n",
    "#     # Sobel filter for x and y gradients\n",
    "#     grad_x = cv2.Sobel(image_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "#     grad_y = cv2.Sobel(image_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "#     # Gradient magnitude and orientation\n",
    "#     grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "#     grad_orientation = np.arctan2(grad_y, grad_x) * (180 / np.pi) % 180 # 0-180 degrees\n",
    "\n",
    "#     # Step 3: Cell-wise Gradient Orientation Histograms (Internal to HoG function)\n",
    "#     # The HoG visualization itself shows this cell structure and orientations.\n",
    "\n",
    "#     # Step 4: HoG Descriptors and Visualization\n",
    "#     hog_features, hog_image = hog(image_gray, \n",
    "#                                   orientations=orientations, \n",
    "#                                   pixels_per_cell=pixels_per_cell,\n",
    "#                                   cells_per_block=cells_per_block, \n",
    "#                                   visualize=True, \n",
    "#                                   feature_vector=True, # For the final feature vector\n",
    "#                                   block_norm='L2-Hys')\n",
    "\n",
    "#     # Visualization\n",
    "#     fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "#     axs[0, 0].imshow(image_rgb)\n",
    "#     axs[0, 0].set_title('1. Original Image (RGB)')\n",
    "#     axs[0, 0].axis('off')\n",
    "\n",
    "#     axs[0, 1].imshow(image_gray, cmap='gray')\n",
    "#     axs[0, 1].set_title('1b. Grayscale Image')\n",
    "#     axs[0, 1].axis('off')\n",
    "\n",
    "#     axs[0, 2].imshow(grad_magnitude, cmap='viridis') # Gradient magnitude\n",
    "#     axs[0, 2].set_title('2a. Gradient Magnitude (Approx.)')\n",
    "#     axs[0, 2].axis('off')\n",
    "    \n",
    "#     axs[1, 0].imshow(grad_orientation, cmap='hsv') # Gradient orientation (hsv often good for angles)\n",
    "#     axs[1, 0].set_title('2b. Gradient Orientation (Approx.)')\n",
    "#     axs[1, 0].axis('off')\n",
    "    \n",
    "#     if hog_image is not None:\n",
    "#         hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10)) # Rescale for better visibility\n",
    "#         axs[1, 1].imshow(hog_image_rescaled, cmap='gray')\n",
    "#         axs[1, 1].set_title(f'3. HoG Descriptor\\n(ppc={pixels_per_cell})')\n",
    "#         axs[1, 1].axis('off')\n",
    "#     else:\n",
    "#         axs[1, 1].text(0.5, 0.5, 'HoG Image Not Available', ha='center', va='center')\n",
    "#         axs[1, 1].set_title('3. HoG Descriptor')\n",
    "#         axs[1, 1].axis('off')\n",
    "\n",
    "#     if hog_features is not None:\n",
    "#         axs[1, 2].plot(hog_features[:min(200, len(hog_features))]) # Plot first 200 features\n",
    "#         axs[1, 2].set_title(f'4. HoG Feature Vector\\n(First {min(200, len(hog_features))} / Total {len(hog_features)})')\n",
    "#         axs[1, 2].set_xlabel('Feature Index')\n",
    "#         axs[1, 2].set_ylabel('Value')\n",
    "#     else:\n",
    "#         axs[1,2].text(0.5,0.5, \"HoG Features\\nNot Available\", ha='center', va='center')\n",
    "#         axs[1,2].axis('off')\n",
    "\n",
    "\n",
    "#     plt.suptitle('HoG Feature Extraction Stages', fontsize=16)\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"\\nHoG Process Steps:\")\n",
    "#     print(\"  1. (Optional) Gamma correction and normalization.\")\n",
    "#     print(\"  2. Conversion of the image to grayscale.\")\n",
    "#     print(\"  3. Calculation of gradients (magnitude and orientation).\")\n",
    "#     print(\"  4. Division of the image into small cells.\")\n",
    "#     print(\"  5. Creation of a histogram of gradient orientations for each cell.\")\n",
    "#     print(\"  6. Grouping of cells into larger blocks.\")\n",
    "#     print(\"  7. Normalization of blocks (to reduce sensitivity to illumination and contrast changes).\")\n",
    "#     print(\"  8. Concatenation of histograms from all blocks to form the final feature vector.\")\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### 3. Gabor Filters: Staged Visualization Function\n",
    "\n",
    "# # %%\n",
    "# def visualize_gabor_stages(image_bgr, num_orientations=4, frequencies_to_show=(0.1, 0.4), sigma_to_show=1.0):\n",
    "#     \"\"\"\n",
    "#     Visualizes the application of Gabor filters and their responses on a BGR image.\n",
    "#     Shows filter responses for different orientations at specified frequencies and a sigma.\n",
    "#     \"\"\"\n",
    "#     if image_bgr is None:\n",
    "#         print(\"Input image cannot be None.\")\n",
    "#         return\n",
    "\n",
    "#     # Step 1: Original Image and Convert to Grayscale\n",
    "#     image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "#     image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY) # skimage.color.rgb2gray(image_rgb)\n",
    "#     # Ensure image_gray is 2D\n",
    "#     if len(image_gray.shape) == 3: \n",
    "#         image_gray = color.rgb2gray(image_gray)\n",
    "\n",
    "\n",
    "#     # Step 2: Gabor Filter Bank Creation (Conceptual)\n",
    "#     # In practice, filtering is done directly rather than creating and then convolving kernels for visualization.\n",
    "\n",
    "#     # Step 3: Apply Filters and Get Responses\n",
    "#     num_freqs_to_show = len(frequencies_to_show)\n",
    "#     total_plots_per_freq = num_orientations + 1 # +1 for the original grayscale image\n",
    "    \n",
    "#     fig_height_per_freq = 3\n",
    "#     fig, all_axs = plt.subplots(num_freqs_to_show, total_plots_per_freq, \n",
    "#                                 figsize=(total_plots_per_freq * 2.5, num_freqs_to_show * fig_height_per_freq),\n",
    "#                                 squeeze=False) # Ensure all_axs is always a 2D array\n",
    "\n",
    "#     print(f\"Gabor Filter Application (Sigma={sigma_to_show}):\")\n",
    "#     all_gabor_features_example = []\n",
    "\n",
    "#     for i, frequency in enumerate(frequencies_to_show):\n",
    "#         axs_row = all_axs[i, :]\n",
    "        \n",
    "#         axs_row[0].imshow(image_gray, cmap='gray')\n",
    "#         axs_row[0].set_title(f'Grayscale\\n(Row for Freq={frequency:.2f})')\n",
    "#         axs_row[0].axis('off')\n",
    "\n",
    "#         print(f\"\\n  Frequency: {frequency:.2f}\")\n",
    "#         for k_orient in range(num_orientations):\n",
    "#             theta = k_orient / float(num_orientations) * np.pi\n",
    "            \n",
    "#             filt_real, filt_imag = filters.gabor(image_gray, frequency=frequency, theta=theta,\n",
    "#                                                  sigma_x=sigma_to_show, sigma_y=sigma_to_show)\n",
    "            \n",
    "#             magnitude = np.sqrt(filt_real**2 + filt_imag**2)\n",
    "            \n",
    "#             mean_mag = np.mean(magnitude)\n",
    "#             std_mag = np.std(magnitude)\n",
    "#             all_gabor_features_example.extend([mean_mag, std_mag])\n",
    "\n",
    "#             if k_orient < total_plots_per_freq -1 : # Check bounds for axes\n",
    "#                 ax_current = axs_row[k_orient + 1]\n",
    "#                 ax_current.imshow(magnitude, cmap='viridis') # 'viridis' or 'gray'\n",
    "#                 ax_current.set_title(f'Mag. $\\\\theta$={theta*180/np.pi:.0f}$^\\\\circ$', fontsize=9)\n",
    "#                 ax_current.axis('off')\n",
    "        \n",
    "#         # Turn off any extra axes in the row if num_orientations is less than subplot cols-1\n",
    "#         for k_extra in range(num_orientations + 1, total_plots_per_freq):\n",
    "#             if k_extra < len(axs_row):\n",
    "#                 axs_row[k_extra].axis('off')\n",
    "\n",
    "#     plt.suptitle(f'Gabor Filter Responses (Orientations & Frequencies, $\\\\sigma$={sigma_to_show})', fontsize=16)\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(\"\\nExample Gabor Feature Vector (Mean and Std Dev of Magnitudes):\")\n",
    "#     print(f\"  Total {len(all_gabor_features_example)} features (2 per filter: mean, std)\")\n",
    "#     print(f\"  First 10 features: {np.array(all_gabor_features_example)[:10]}\")\n",
    "#     print(\"\\nGabor Filtering Process:\")\n",
    "#     print(\"  1. Image is typically converted to grayscale.\")\n",
    "#     print(\"  2. A Gabor filter bank is defined with different orientations, frequencies, and scales (sigma).\")\n",
    "#     print(\"  3. Each filter is applied to the image (convolution).\")\n",
    "#     print(\"  4. Statistical features (e.g., mean, standard deviation, energy) are extracted from each filtered image (usually from the magnitude response).\")\n",
    "#     print(\"  5. These features are concatenated to form the final Gabor feature vector.\")\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### Running the Staged Visualizations\n",
    "\n",
    "# # %%\n",
    "# # --- Example Usage of Staged Visualization Functions ---\n",
    "\n",
    "# # Ensure X_train_images_bgr, y_train_final, label_mapping, IMG_WIDTH, IMG_HEIGHT are defined from Part 0\n",
    "# # (This code is from your `assignment42.ipynb` and assumes those variables are in the global scope)\n",
    "\n",
    "# if 'X_train_images_bgr' in globals() and X_train_images_bgr.any(): # .any() checks if array is not empty\n",
    "#     # Select a random sample image from the training set\n",
    "#     sample_index = random.randint(0, X_train_images_bgr.shape[0] - 1)\n",
    "#     sample_image_bgr_for_viz = X_train_images_bgr[sample_index].copy()\n",
    "    \n",
    "#     print(f\"Selected Sample Image Index: {sample_index}\")\n",
    "#     if 'y_train_final' in globals() and y_train_final.size > sample_index and \\\n",
    "#        'label_mapping' in globals() and label_mapping:\n",
    "#         sample_label = y_train_final[sample_index]\n",
    "#         sample_class_name = label_mapping.get(sample_label, f\"Label {sample_label}\")\n",
    "#         print(f\"Class: {sample_class_name}\")\n",
    "    \n",
    "#     # Display the chosen sample image\n",
    "#     plt.figure(figsize=(4,4)) # Increased size slightly\n",
    "#     plt.imshow(cv2.cvtColor(sample_image_bgr_for_viz, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title(\"Sample Image for Staged Visualization\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "#     # --- 1. Visualize HSV Stages ---\n",
    "#     print(\"\\n\" + \"=\"*10 + \" 1. HSV Transformation Stages \" + \"=\"*10)\n",
    "#     visualize_hsv_stages(sample_image_bgr_for_viz.copy()) # Pass a copy\n",
    "\n",
    "#     # --- 2. Visualize HoG Stages ---\n",
    "#     print(\"\\n\" + \"=\"*10 + \" 2. HoG Feature Extraction Stages \" + \"=\"*10)\n",
    "#     # Adjust HoG parameters based on your image size (IMG_WIDTH, IMG_HEIGHT from Part 0)\n",
    "#     # These IMG_WIDTH/HEIGHT variables are assumed to be defined from your notebook's Part 0.1.\n",
    "#     if 'IMG_WIDTH' in globals() and IMG_WIDTH >= 128:\n",
    "#         hog_pixels_per_cell_viz = (16, 16)\n",
    "#     elif 'IMG_WIDTH' in globals() and IMG_WIDTH >= 64:\n",
    "#         hog_pixels_per_cell_viz = (8, 8)\n",
    "#     else: # For smaller images like 28x28 or 32x32\n",
    "#         hog_pixels_per_cell_viz = (4, 4) \n",
    "        \n",
    "#     visualize_hog_stages(sample_image_bgr_for_viz.copy(), \n",
    "#                          pixels_per_cell=hog_pixels_per_cell_viz, \n",
    "#                          cells_per_block=(2,2), \n",
    "#                          orientations=9)\n",
    "\n",
    "#     # --- 3. Visualize Gabor Filter Stages ---\n",
    "#     print(\"\\n\" + \"=\"*10 + \" 3. Gabor Filter Application Stages \" + \"=\"*10)\n",
    "#     # You can reduce num_orientations or frequencies_to_show if it produces too many plots\n",
    "#     visualize_gabor_stages(sample_image_bgr_for_viz.copy(), \n",
    "#                            num_orientations=4,       # e.g., 4 or 6 orientations for visualization\n",
    "#                            frequencies_to_show=(0.1, 0.4), # Show a couple of frequencies\n",
    "#                            sigma_to_show=2.0)         # A representative sigma\n",
    "\n",
    "# else:\n",
    "#     print(\"X_train_images_bgr is not defined or is empty.\")\n",
    "#     print(\"Please ensure Part 0 (Data Loading and Preprocessing) has been executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3: Testing Feature Extraction Algorithms with Different Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized parallel processing with 12 cores available...\n",
      "Core allocation: HSV (1 core), HoG (1 core), Gabor (10 cores)\n",
      "\n",
      "=== PHASE 1: FEATURE EXTRACTION ===\n",
      "Extracting HSV_Hist features for train set (single core)...\n",
      "Extracting HSV_Hist features for test set (single core)...\n",
      "\n",
      "Test features shape: (2000, 128)HSV_Hist test feature extraction completed in 0.19 seconds.\n",
      "HSV_Hist train feature extraction completed in 0.89 seconds.\n",
      "Train features shape: (10000, 128)\n",
      "Extracting HoG features for train set (single core)...\n",
      "Extracting HoG features for test set (single core)...\n",
      "HoG test feature extraction completed in 5.08 seconds.\n",
      "Test features shape: (2000, 1764)\n",
      "HoG train feature extraction completed in 24.15 seconds.\n",
      "Train features shape: (10000, 1764)\n",
      "\n",
      "Starting Gabor feature extraction with 10 cores...\n",
      "Extracting Gabor features for train set using 10 cores...\n",
      "Split 10000 images into 10 chunks of ~1000 images each\n",
      "Processing Gabor chunk 1 (images 0 to 999)\n",
      "Processing Gabor chunk 2 (images 1000 to 1999)\n",
      "Processing Gabor chunk 3 (images 2000 to 2999)\n",
      "Processing Gabor chunk 4 (images 3000 to 3999)\n",
      "Processing Gabor chunk 5 (images 4000 to 4999)\n",
      "Processing Gabor chunk 6 (images 5000 to 5999)\n",
      "Processing Gabor chunk 7 (images 6000 to 6999)\n",
      "Processing Gabor chunk 8 (images 7000 to 7999)\n",
      "Processing Gabor chunk 9 (images 8000 to 8999)\n",
      "Processing Gabor chunk 10 (images 9000 to 9999)\n",
      "Gabor chunk 2 completed\n",
      "Gabor chunk 8 completed\n",
      "Gabor chunk 5 completed\n",
      "Gabor chunk 4 completed\n",
      "Gabor chunk 6 completed\n",
      "Gabor chunk 10 completed\n",
      "Gabor chunk 1 completed\n",
      "Gabor chunk 7 completed\n",
      "Gabor chunk 3 completed\n",
      "Gabor chunk 9 completed\n",
      "Gabor train feature extraction completed in 404.75 seconds.\n",
      "Train features shape: (10000, 96)\n",
      "Extracting Gabor features for test set using 10 cores...\n",
      "Split 2000 images into 10 chunks of ~200 images each\n",
      "Processing Gabor chunk 1 (images 0 to 199)\n",
      "Processing Gabor chunk 2 (images 200 to 399)\n",
      "Processing Gabor chunk 3 (images 400 to 599)\n",
      "Processing Gabor chunk 4 (images 600 to 799)\n",
      "Processing Gabor chunk 5 (images 800 to 999)\n",
      "Processing Gabor chunk 6 (images 1000 to 1199)\n",
      "Processing Gabor chunk 7 (images 1200 to 1399)\n",
      "Processing Gabor chunk 8 (images 1400 to 1599)\n",
      "Processing Gabor chunk 9 (images 1600 to 1799)\n",
      "Processing Gabor chunk 10 (images 1800 to 1999)\n",
      "Gabor chunk 1 completed\n",
      "Gabor chunk 4 completed\n",
      "Gabor chunk 6 completed\n",
      "Gabor chunk 5 completed\n",
      "Gabor chunk 2 completed\n",
      "Gabor chunk 9 completed\n",
      "Gabor chunk 3 completed\n",
      "Gabor chunk 10 completed\n",
      "Gabor chunk 7 completed\n",
      "Gabor chunk 8 completed\n",
      "Gabor test feature extraction completed in 77.51 seconds.\n",
      "Test features shape: (2000, 96)\n",
      "\n",
      "Feature extraction completed. Extracted features for: ['HSV_Hist_test', 'HSV_Hist_train', 'HoG_test', 'HoG_train', 'Gabor_train', 'Gabor_test']\n",
      "\n",
      "=== PHASE 2: MODEL TRAINING AND EVALUATION ===\n",
      "Created 12 training tasks\n",
      "Training SVM with HSV_Hist features...\n",
      "Training RandomForest with HSV_Hist features...\n",
      "Training LogisticRegression with HSV_Hist features...\n",
      "Training MLP with HSV_Hist features...\n",
      "Training SVM with HoG features...\n",
      "RandomForest with HSV_Hist training completed in 2.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.pyenv/versions/3.9.22/lib/python3.9/site-packages/sklearn/ensemble/_base.py:168: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with HSV_Hist - Accuracy: 0.6905\n",
      "RandomForest with HSV_Hist - Macro F1: 0.6895\n",
      "Training RandomForest with HoG features...\n",
      "Training LogisticRegression with HoG features...\n",
      "Training MLP with HoG features...\n",
      "Training SVM with Gabor features...\n",
      "Training RandomForest with Gabor features...\n",
      "Training LogisticRegression with Gabor features...\n",
      "Training MLP with Gabor features...\n",
      "RandomForest with Gabor training completed in 6.86 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.pyenv/versions/3.9.22/lib/python3.9/site-packages/sklearn/ensemble/_base.py:168: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with Gabor - Accuracy: 0.3055\n",
      "RandomForest with Gabor - Macro F1: 0.3008\n",
      "RandomForest with HoG training completed in 29.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.pyenv/versions/3.9.22/lib/python3.9/site-packages/sklearn/ensemble/_base.py:168: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with HoG - Accuracy: 0.2095\n",
      "RandomForest with HoG - Macro F1: 0.2072\n",
      "LogisticRegression with Gabor training completed in 39.74 seconds.\n",
      "LogisticRegression with Gabor - Accuracy: 0.2765\n",
      "LogisticRegression with Gabor - Macro F1: 0.2632\n",
      "LogisticRegression with HSV_Hist training completed in 65.56 seconds.\n",
      "LogisticRegression with HSV_Hist - Accuracy: 0.2995\n",
      "LogisticRegression with HSV_Hist - Macro F1: 0.2969\n",
      "SVM with Gabor training completed in 138.97 seconds.\n",
      "SVM with Gabor - Accuracy: 0.2460\n",
      "SVM with Gabor - Macro F1: 0.2383\n",
      "SVM with HSV_Hist training completed in 158.05 seconds.\n",
      "MLP with HSV_Hist training completed in 161.86 seconds.\n",
      "MLP with HSV_Hist - Accuracy: 0.4345\n",
      "MLP with HSV_Hist - Macro F1: 0.4359\n",
      "MLP with Gabor training completed in 156.76 seconds.\n",
      "MLP with Gabor - Accuracy: 0.2855\n",
      "MLP with Gabor - Macro F1: 0.2790\n",
      "SVM with HSV_Hist - Accuracy: 0.3250\n",
      "SVM with HSV_Hist - Macro F1: 0.3247\n",
      "MLP with HoG training completed in 162.50 seconds.\n",
      "MLP with HoG - Accuracy: 0.2260\n",
      "MLP with HoG - Macro F1: 0.2236\n",
      "LogisticRegression with HoG training completed in 771.25 seconds.\n",
      "LogisticRegression with HoG - Accuracy: 0.1455\n",
      "LogisticRegression with HoG - Macro F1: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.pyenv/versions/3.9.22/lib/python3.9/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with HoG training completed in 832.03 seconds.\n",
      "SVM with HoG - Accuracy: 0.2865\n",
      "SVM with HoG - Macro F1: 0.2807\n",
      "\n",
      "=== PART 1: ALL PARALLEL PROCESSES COMPLETED ===\n",
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "\n",
      "Top performing combinations:\n",
      "HSV + Hist_RandomForest: 0.6905\n",
      "  Macro F1-Score: 0.6895\n",
      "\n",
      "HSV + Hist_MLP: 0.4345\n",
      "  Macro F1-Score: 0.4359\n",
      "\n",
      "HSV + Hist_SVM: 0.3250\n",
      "  Macro F1-Score: 0.3247\n",
      "\n",
      "Gabor + RandomForest: 0.3055\n",
      "  Macro F1-Score: 0.3008\n",
      "\n",
      "HSV + Hist_LogisticRegression: 0.2995\n",
      "  Macro F1-Score: 0.2969\n",
      "\n",
      "HoG + SVM: 0.2865\n",
      "  Macro F1-Score: 0.2807\n",
      "\n",
      "Gabor + MLP: 0.2855\n",
      "  Macro F1-Score: 0.2790\n",
      "\n",
      "Gabor + LogisticRegression: 0.2765\n",
      "  Macro F1-Score: 0.2632\n",
      "\n",
      "Gabor + SVM: 0.2460\n",
      "  Macro F1-Score: 0.2383\n",
      "\n",
      "HoG + MLP: 0.2260\n",
      "  Macro F1-Score: 0.2236\n",
      "\n",
      "🏆 BEST COMBINATION: HSV + Hist_RandomForest\n",
      "   Accuracy: 0.6905\n",
      "   Macro F1-Score: 0.6895\n",
      "\n",
      "Processing completed!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# %%\n",
    "# --- Helper function for chunked Gabor processing ---\n",
    "def extract_gabor_features_chunk(args):\n",
    "    \"\"\"\n",
    "    Extract Gabor features for a chunk of images\n",
    "    Args: (image_chunk, start_idx, chunk_id, feature_extractor_func)\n",
    "    Returns: (chunk_id, start_idx, features_list)\n",
    "    \"\"\"\n",
    "    image_chunk, start_idx, chunk_id, feature_extractor_func = args\n",
    "    print(f\"Processing Gabor chunk {chunk_id + 1} (images {start_idx} to {start_idx + len(image_chunk) - 1})\")\n",
    "    \n",
    "    features_list = []\n",
    "    for img in image_chunk:\n",
    "        features = feature_extractor_func(img)\n",
    "        features_list.append(features)\n",
    "    \n",
    "    print(f\"Gabor chunk {chunk_id + 1} completed\")\n",
    "    return chunk_id, start_idx, features_list\n",
    "\n",
    "# %%\n",
    "# --- Phase 1: Feature Extraction Functions ---\n",
    "def extract_features_single_core(feature_name, feature_extractor_func, X_images, dataset_type=\"train\"):\n",
    "    \"\"\"\n",
    "    Extract features using single core (for HSV and HoG)\n",
    "    \"\"\"\n",
    "    print(f\"Extracting {feature_name} features for {dataset_type} set (single core)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    features_list = [feature_extractor_func(img) for img in X_images]\n",
    "    \n",
    "    # Filter out failed extractions (None values)\n",
    "    successful_indices = [i for i, f in enumerate(features_list) if f is not None]\n",
    "    \n",
    "    if len(successful_indices) == 0:\n",
    "        print(f\"ERROR: No {dataset_type} features successfully extracted for {feature_name}\")\n",
    "        return feature_name, dataset_type, None, None\n",
    "    \n",
    "    features_array = np.array([features_list[i] for i in successful_indices])\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"{feature_name} {dataset_type} feature extraction completed in {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"{dataset_type.capitalize()} features shape: {features_array.shape}\")\n",
    "    \n",
    "    return feature_name, dataset_type, features_array, successful_indices\n",
    "\n",
    "def extract_gabor_features_multicore(X_images, dataset_type=\"train\", num_cores=10):\n",
    "    \"\"\"\n",
    "    Extract Gabor features using multiple cores by splitting the dataset\n",
    "    \"\"\"\n",
    "    print(f\"Extracting Gabor features for {dataset_type} set using {num_cores} cores...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Split images into chunks for parallel processing\n",
    "    total_images = len(X_images)\n",
    "    chunk_size = max(1, total_images // num_cores)\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, total_images, chunk_size):\n",
    "        end_idx = min(i + chunk_size, total_images)\n",
    "        image_chunk = X_images[i:end_idx]\n",
    "        chunks.append((image_chunk, i, len(chunks), extract_gabor_features_single_image))\n",
    "    \n",
    "    print(f\"Split {total_images} images into {len(chunks)} chunks of ~{chunk_size} images each\")\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    try:\n",
    "        with Pool(processes=num_cores) as pool:\n",
    "            chunk_results = pool.map(extract_gabor_features_chunk, chunks)\n",
    "        \n",
    "        # Combine results from all chunks\n",
    "        # Sort by chunk_id to maintain order\n",
    "        chunk_results.sort(key=lambda x: x[0])\n",
    "        \n",
    "        combined_features_list = []\n",
    "        for chunk_id, start_idx, features_list in chunk_results:\n",
    "            combined_features_list.extend(features_list)\n",
    "        \n",
    "        # Filter out failed extractions (None values)\n",
    "        successful_indices = [i for i, f in enumerate(combined_features_list) if f is not None]\n",
    "        \n",
    "        if len(successful_indices) == 0:\n",
    "            print(f\"ERROR: No {dataset_type} Gabor features successfully extracted\")\n",
    "            return \"Gabor\", dataset_type, None, None\n",
    "        \n",
    "        features_array = np.array([combined_features_list[i] for i in successful_indices])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Gabor {dataset_type} feature extraction completed in {end_time - start_time:.2f} seconds.\")\n",
    "        print(f\"{dataset_type.capitalize()} features shape: {features_array.shape}\")\n",
    "        \n",
    "        return \"Gabor\", dataset_type, features_array, successful_indices\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during Gabor feature extraction: {e}\")\n",
    "        return \"Gabor\", dataset_type, None, None\n",
    "\n",
    "# %%\n",
    "# --- Phase 2: Parallel Model Training and Evaluation ---\n",
    "def train_and_evaluate_model(args):\n",
    "    \"\"\"\n",
    "    Train and evaluate a single model with given features\n",
    "    Args: (feature_name, model_name, model_instance, X_train_features, y_train_filtered, \n",
    "           X_test_features, y_test_filtered, target_names)\n",
    "    \"\"\"\n",
    "    (feature_name, model_name, model_instance, X_train_features, y_train_filtered,\n",
    "     X_test_features, y_test_filtered, target_names) = args\n",
    "    \n",
    "    print(f\"Training {model_name} with {feature_name} features...\")\n",
    "    \n",
    "    # Create pipeline with scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('classifier', model_instance)\n",
    "    ])\n",
    "    \n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Validation checks\n",
    "        if X_train_features.shape[1] != X_test_features.shape[1]:\n",
    "            return (feature_name, model_name, {\"error\": \"Feature dimension mismatch\"})\n",
    "        \n",
    "        if X_train_features.shape[0] == 0 or y_train_filtered.shape[0] == 0:\n",
    "            return (feature_name, model_name, {\"error\": \"Empty training data\"})\n",
    "        \n",
    "        if len(np.unique(y_train_filtered)) < 2:\n",
    "            return (feature_name, model_name, {\"error\": \"Less than 2 classes in training data\"})\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train_features, y_train_filtered)\n",
    "        \n",
    "        end_train_time = time.time()\n",
    "        print(f\"{model_name} with {feature_name} training completed in {end_train_time - start_train_time:.2f} seconds.\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        if X_test_features.shape[0] > 0 and y_test_filtered.shape[0] > 0:\n",
    "            y_pred = pipeline.predict(X_test_features)\n",
    "            accuracy = accuracy_score(y_test_filtered, y_pred)\n",
    "            \n",
    "            try:\n",
    "                # Generate classification report\n",
    "                unique_labels = sorted(list(set(y_train_filtered) | set(y_test_filtered)))\n",
    "                current_target_names = [target_names[i] for i in unique_labels if i < len(target_names)]\n",
    "                \n",
    "                report = classification_report(\n",
    "                    y_test_filtered, y_pred, \n",
    "                    labels=unique_labels, \n",
    "                    target_names=current_target_names, \n",
    "                    zero_division=0, \n",
    "                    output_dict=True\n",
    "                )\n",
    "                \n",
    "                print(f\"{model_name} with {feature_name} - Accuracy: {accuracy:.4f}\")\n",
    "                if 'macro avg' in report:\n",
    "                    print(f\"{model_name} with {feature_name} - Macro F1: {report['macro avg']['f1-score']:.4f}\")\n",
    "                \n",
    "                return (feature_name, model_name, {\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"classification_report_dict\": report\n",
    "                })\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Could not generate classification report for {model_name} with {feature_name}: {e}\")\n",
    "                return (feature_name, model_name, {\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"classification_report_dict\": {\"error\": str(e), \"accuracy_manual\": accuracy}\n",
    "                })\n",
    "        else:\n",
    "            return (feature_name, model_name, {\"error\": \"Empty test features or labels\"})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR training {model_name} with {feature_name}: {e}\")\n",
    "        return (feature_name, model_name, {\"error\": str(e)})\n",
    "\n",
    "# %%\n",
    "# --- Main Execution Code ---\n",
    "# Feature extractors and ML models\n",
    "feature_extractors_to_test = {\n",
    "    \"HSV_Hist\": extract_hsv_histogram_single_image,\n",
    "    \"HoG\": extract_hog_features_single_image,\n",
    "    \"Gabor\": extract_gabor_features_single_image\n",
    "}\n",
    "\n",
    "ml_models = get_ml_models()  # MLP included\n",
    "\n",
    "# Check if data is available\n",
    "if not all(hasattr(arr, 'size') and arr.size > 0 for arr in [X_train_images_bgr, y_train_final, X_test_images_bgr, y_test_final]):\n",
    "    print(\"One or more data arrays are empty or not initialized. Skipping Part 1.\")\n",
    "    part1_results = {}\n",
    "else:\n",
    "    print(f\"Starting optimized parallel processing with {cpu_count()} cores available...\")\n",
    "    print(\"Core allocation: HSV (1 core), HoG (1 core), Gabor (10 cores)\")\n",
    "    \n",
    "    # ===== PHASE 1: PARALLEL FEATURE EXTRACTION =====\n",
    "    print(\"\\n=== PHASE 1: FEATURE EXTRACTION ===\")\n",
    "    \n",
    "    extracted_features = {}\n",
    "    successful_indices = {}\n",
    "    \n",
    "    try:\n",
    "        # Start HSV and HoG feature extraction in parallel (2 cores total)\n",
    "        with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "            # Submit HSV tasks\n",
    "            hsv_train_future = executor.submit(\n",
    "                extract_features_single_core, \"HSV_Hist\", \n",
    "                extract_hsv_histogram_single_image, X_train_images_bgr, \"train\"\n",
    "            )\n",
    "            hsv_test_future = executor.submit(\n",
    "                extract_features_single_core, \"HSV_Hist\", \n",
    "                extract_hsv_histogram_single_image, X_test_images_bgr, \"test\"\n",
    "            )\n",
    "            \n",
    "            # Submit HoG tasks\n",
    "            hog_train_future = executor.submit(\n",
    "                extract_features_single_core, \"HoG\", \n",
    "                extract_hog_features_single_image, X_train_images_bgr, \"train\"\n",
    "            )\n",
    "            hog_test_future = executor.submit(\n",
    "                extract_features_single_core, \"HoG\", \n",
    "                extract_hog_features_single_image, X_test_images_bgr, \"test\"\n",
    "            )\n",
    "            \n",
    "            # Process HSV and HoG results\n",
    "            hsv_hog_futures = [hsv_train_future, hsv_test_future, hog_train_future, hog_test_future]\n",
    "            \n",
    "            for future in as_completed(hsv_hog_futures):\n",
    "                feat_name, dataset_type, features_array, indices = future.result()\n",
    "                if features_array is not None:\n",
    "                    extracted_features[f\"{feat_name}_{dataset_type}\"] = features_array\n",
    "                    successful_indices[f\"{feat_name}_{dataset_type}\"] = indices\n",
    "                else:\n",
    "                    print(f\"Failed to extract {feat_name} features for {dataset_type} set\")\n",
    "        \n",
    "        # Extract Gabor features using 10 cores\n",
    "        print(\"\\nStarting Gabor feature extraction with 10 cores...\")\n",
    "        \n",
    "        # Extract Gabor train features\n",
    "        gabor_train_result = extract_gabor_features_multicore(X_train_images_bgr, \"train\", num_cores=10)\n",
    "        feat_name, dataset_type, features_array, indices = gabor_train_result\n",
    "        if features_array is not None:\n",
    "            extracted_features[f\"{feat_name}_{dataset_type}\"] = features_array\n",
    "            successful_indices[f\"{feat_name}_{dataset_type}\"] = indices\n",
    "        else:\n",
    "            print(f\"Failed to extract {feat_name} features for {dataset_type} set\")\n",
    "        \n",
    "        # Extract Gabor test features\n",
    "        gabor_test_result = extract_gabor_features_multicore(X_test_images_bgr, \"test\", num_cores=10)\n",
    "        feat_name, dataset_type, features_array, indices = gabor_test_result\n",
    "        if features_array is not None:\n",
    "            extracted_features[f\"{feat_name}_{dataset_type}\"] = features_array\n",
    "            successful_indices[f\"{feat_name}_{dataset_type}\"] = indices\n",
    "        else:\n",
    "            print(f\"Failed to extract {feat_name} features for {dataset_type} set\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature extraction: {e}\")\n",
    "        extracted_features = {}\n",
    "    \n",
    "    print(f\"\\nFeature extraction completed. Extracted features for: {list(extracted_features.keys())}\")\n",
    "    \n",
    "    # ===== PHASE 2: PARALLEL MODEL TRAINING (12 cores) =====\n",
    "    print(\"\\n=== PHASE 2: MODEL TRAINING AND EVALUATION ===\")\n",
    "    \n",
    "    if extracted_features:\n",
    "        # Prepare training tasks (3 features × 4 models = 12 tasks)\n",
    "        training_tasks = []\n",
    "        \n",
    "        feature_name_mapping = {\n",
    "            \"HSV_Hist\": \"HSV_Hist\",\n",
    "            \"HoG\": \"HoG\", \n",
    "            \"Gabor\": \"Gabor\"\n",
    "        }\n",
    "        \n",
    "        for original_feat_name, mapped_feat_name in feature_name_mapping.items():\n",
    "            train_key = f\"{mapped_feat_name}_train\"\n",
    "            test_key = f\"{mapped_feat_name}_test\"\n",
    "            \n",
    "            if train_key in extracted_features and test_key in extracted_features:\n",
    "                # Get filtered labels based on successful feature extractions\n",
    "                y_train_filtered = y_train_final[successful_indices[train_key]]\n",
    "                y_test_filtered = y_test_final[successful_indices[test_key]]\n",
    "                \n",
    "                # Create training tasks for all models with this feature\n",
    "                for model_name, model_instance in ml_models.items():\n",
    "                    task = (\n",
    "                        mapped_feat_name, model_name, model_instance,\n",
    "                        extracted_features[train_key], y_train_filtered,\n",
    "                        extracted_features[test_key], y_test_filtered,\n",
    "                        target_names_part1\n",
    "                    )\n",
    "                    training_tasks.append(task)\n",
    "        \n",
    "        print(f\"Created {len(training_tasks)} training tasks\")\n",
    "        \n",
    "        # Execute all training tasks in parallel using all 12 cores\n",
    "        part1_results = {}\n",
    "        \n",
    "        if training_tasks:\n",
    "            try:\n",
    "                with Pool(processes=12) as pool:  # Use all 12 cores for model training\n",
    "                    training_results = pool.map(train_and_evaluate_model, training_tasks)\n",
    "                \n",
    "                # Organize results\n",
    "                for feat_name, model_name, result in training_results:\n",
    "                    key = f\"{feat_name}_{model_name}\"\n",
    "                    part1_results[key] = result\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error during model training: {e}\")\n",
    "                part1_results = {}\n",
    "        else:\n",
    "            print(\"No training tasks to execute\")\n",
    "            part1_results = {}\n",
    "    else:\n",
    "        print(\"No features extracted successfully. Skipping model training.\")\n",
    "        part1_results = {}\n",
    "\n",
    "print(\"\\n=== PART 1: ALL PARALLEL PROCESSES COMPLETED ===\")\n",
    "\n",
    "# %%\n",
    "# --- Results Summary ---\n",
    "if part1_results:\n",
    "    print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "    \n",
    "    # Sort results by accuracy for better readability\n",
    "    sorted_results = []\n",
    "    for key, result in part1_results.items():\n",
    "        if isinstance(result, dict) and \"accuracy\" in result:\n",
    "            sorted_results.append((key, result[\"accuracy\"], result))\n",
    "        else:\n",
    "            print(f\"{key}: {result}\")\n",
    "    \n",
    "    # Sort by accuracy (descending)\n",
    "    sorted_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop performing combinations:\")\n",
    "    for key, accuracy, result in sorted_results[:10]:  # Show top 10\n",
    "        feature_name, model_name = key.split('_', 1)\n",
    "        print(f\"{feature_name} + {model_name}: {accuracy:.4f}\")\n",
    "        \n",
    "        if \"classification_report_dict\" in result and \"macro avg\" in result[\"classification_report_dict\"]:\n",
    "            macro_f1 = result[\"classification_report_dict\"][\"macro avg\"][\"f1-score\"]\n",
    "            print(f\"  Macro F1-Score: {macro_f1:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Find best overall combination\n",
    "    if sorted_results:\n",
    "        best_combo, best_accuracy, best_result = sorted_results[0]\n",
    "        best_feature, best_model = best_combo.split('_', 1)\n",
    "        print(f\"🏆 BEST COMBINATION: {best_feature} + {best_model}\")\n",
    "        print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
    "        \n",
    "        if \"classification_report_dict\" in best_result and \"macro avg\" in best_result[\"classification_report_dict\"]:\n",
    "            best_macro_f1 = best_result[\"classification_report_dict\"][\"macro avg\"][\"f1-score\"]\n",
    "            print(f\"   Macro F1-Score: {best_macro_f1:.4f}\")\n",
    "else:\n",
    "    print(\"No results to display.\")\n",
    "\n",
    "print(\"\\nProcessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Visualization of Results ---\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# if part1_results:\n",
    "#     # Create DataFrame from results for visualization\n",
    "#     data_for_plot = []\n",
    "    \n",
    "#     for key, result in part1_results.items():\n",
    "#         if isinstance(result, dict) and \"accuracy\" in result:\n",
    "#             # Split the key to get feature name and model name\n",
    "#             parts = key.split('_')\n",
    "#             if len(parts) >= 2:\n",
    "#                 # Handle cases where feature name might have underscores (like HSV_Hist)\n",
    "#                 if parts[0] == 'HSV' and len(parts) > 2:\n",
    "#                     feature_name = 'HSV_Hist'\n",
    "#                     model_name = '_'.join(parts[2:])\n",
    "#                 else:\n",
    "#                     feature_name = parts[0]\n",
    "#                     model_name = '_'.join(parts[1:])\n",
    "                \n",
    "#                 accuracy = result[\"accuracy\"]\n",
    "                \n",
    "#                 # Get macro F1 if available\n",
    "#                 macro_f1 = None\n",
    "#                 if (\"classification_report_dict\" in result and \n",
    "#                     isinstance(result[\"classification_report_dict\"], dict) and\n",
    "#                     \"macro avg\" in result[\"classification_report_dict\"]):\n",
    "#                     macro_f1 = result[\"classification_report_dict\"][\"macro avg\"][\"f1-score\"]\n",
    "                \n",
    "#                 data_for_plot.append({\n",
    "#                     'Feature Set': feature_name,\n",
    "#                     'ML Model': model_name,\n",
    "#                     'Test Accuracy': accuracy,\n",
    "#                     'Macro F1-Score': macro_f1 if macro_f1 is not None else 0\n",
    "#                 })\n",
    "    \n",
    "#     if data_for_plot:\n",
    "#         # Create DataFrame\n",
    "#         df_results_part1 = pd.DataFrame(data_for_plot)\n",
    "        \n",
    "#         # Create the accuracy comparison chart\n",
    "#         plt.figure(figsize=(15, 8))\n",
    "#         sns.barplot(x=\"ML Model\", y=\"Test Accuracy\", hue=\"Feature Set\", \n",
    "#                    data=df_results_part1, palette=\"viridis\")\n",
    "#         plt.title(\"Part 1: Model Test Accuracy Comparison by Feature Set\", fontsize=16)\n",
    "#         plt.ylabel(\"Test Accuracy\", fontsize=12)\n",
    "#         plt.xlabel(\"Machine Learning Model\", fontsize=12)\n",
    "#         plt.xticks(rotation=45, ha=\"right\")\n",
    "#         plt.legend(title=\"Feature Set\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#         plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Create a second chart for F1-Score comparison\n",
    "#         plt.figure(figsize=(15, 8))\n",
    "#         sns.barplot(x=\"ML Model\", y=\"Macro F1-Score\", hue=\"Feature Set\", \n",
    "#                    data=df_results_part1, palette=\"plasma\")\n",
    "#         plt.title(\"Part 1: Model Macro F1-Score Comparison by Feature Set\", fontsize=16)\n",
    "#         plt.ylabel(\"Macro F1-Score\", fontsize=12)\n",
    "#         plt.xlabel(\"Machine Learning Model\", fontsize=12)\n",
    "#         plt.xticks(rotation=45, ha=\"right\")\n",
    "#         plt.legend(title=\"Feature Set\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#         plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Create a heatmap for better comparison\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "        \n",
    "#         # Pivot the data for heatmap\n",
    "#         heatmap_data = df_results_part1.pivot(index=\"Feature Set\", \n",
    "#                                              columns=\"ML Model\", \n",
    "#                                              values=\"Test Accuracy\")\n",
    "        \n",
    "#         sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', fmt='.3f', \n",
    "#                    cbar_kws={'label': 'Test Accuracy'})\n",
    "#         plt.title(\"Part 1: Accuracy Heatmap - Feature Sets vs ML Models\", fontsize=16)\n",
    "#         plt.xlabel(\"Machine Learning Model\", fontsize=12)\n",
    "#         plt.ylabel(\"Feature Set\", fontsize=12)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Print the DataFrame for reference\n",
    "#         print(\"\\n=== RESULTS DATAFRAME ===\")\n",
    "#         print(df_results_part1.sort_values('Test Accuracy', ascending=False))\n",
    "        \n",
    "#     else:\n",
    "#         print(\"No valid results found for visualization.\")\n",
    "        \n",
    "# else:\n",
    "#     print(\"part1_results dictionary not found or is empty. Cannot generate comparison charts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Principal Component Analysis (PCA) and Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Library Imports and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Applying PCA and Evaluating ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 62\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_collection\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Get list of feature types you extracted in Part 1\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Make sure X_train_dict, X_val_dict, X_test_dict, y_train, y_val, y_test are defined\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# And ml_algorithms_part1 dictionary is defined with your models\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m feature_extraction_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mX_train_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m# e.g., ['color_hist', 'hog', 'sift']\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f_type \u001b[38;5;129;01min\u001b[39;00m feature_extraction_types:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Processing Part 2 for feature type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif # chi2 is an option for non-negative features\n",
    "# Import your ML algorithms from Part 1 (ensure these are the same ones)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Placeholder for your data and models ---\n",
    "# Ensure these variables are correctly loaded/defined from your Part 0 and Part 1\n",
    "# Example:\n",
    "# X_train_dict = {\"color\": train_color_features, \"hog\": train_hog_features, ...}\n",
    "# X_val_dict = {\"color\": val_color_features, \"hog\": val_hog_features, ...} # For tuning k or n_components\n",
    "# X_test_dict = {\"color\": test_color_features, \"hog\": test_hog_features, ...}\n",
    "# y_train, y_val, y_test = your_labels_for_train_val_test_sets\n",
    "\n",
    "# ML algorithms used in Part 1 (use your actual models and their parameters)\n",
    "# ml_algorithms_part1 = {\n",
    "#     \"SVM\": SVC(kernel='linear', C=1, random_state=42),\n",
    "#     \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"NaiveBayes\": GaussianNB()\n",
    "# }\n",
    "\n",
    "# Dictionary to store results from Part 1 (load or ensure this is accessible)\n",
    "# results_part1 = {\n",
    "#     \"color_SVM\": {\"accuracy\": 0.85, \"precision\": 0.84, ...},\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# Dictionary to store results for Part 2\n",
    "results_part2 = {}\n",
    "\n",
    "# Helper function to evaluate models\n",
    "def evaluate_and_store_metrics(model, X_train_proc, y_train_labels, X_test_proc, y_test_labels,\n",
    "                               feature_set_name, dim_reduction_method, algo_identifier, results_collection):\n",
    "    print(f\"Training {algo_identifier} on {feature_set_name} features processed by {dim_reduction_method}...\")\n",
    "    model.fit(X_train_proc, y_train_labels)\n",
    "    predictions = model.predict(X_test_proc)\n",
    "\n",
    "    acc = accuracy_score(y_test_labels, predictions)\n",
    "    prec = precision_score(y_test_labels, predictions, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test_labels, predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_labels, predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    result_key = f\"{feature_set_name}_{dim_reduction_method}_{algo_identifier}\"\n",
    "    results_collection[result_key] = {\n",
    "        \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1\n",
    "    }\n",
    "    print(f\"  Metrics for {result_key}: Accuracy={acc:.4f}, F1={f1:.4f}\")\n",
    "    return results_collection\n",
    "\n",
    "# Get list of feature types you extracted in Part 1\n",
    "# Make sure X_train_dict, X_val_dict, X_test_dict, y_train, y_val, y_test are defined\n",
    "# And ml_algorithms_part1 dictionary is defined with your models\n",
    "\n",
    "feature_extraction_types = list(X_train_dict.keys()) # e.g., ['color_hist', 'hog', 'sift']\n",
    "\n",
    "for f_type in feature_extraction_types:\n",
    "    print(f\"\\n--- Processing Part 2 for feature type: {f_type} ---\")\n",
    "\n",
    "    X_train_current = X_train_dict[f_type]\n",
    "    # X_val_current = X_val_dict[f_type] # Use for hyperparameter tuning (n_components, k)\n",
    "    X_test_current = X_test_dict[f_type]\n",
    "\n",
    "    # 1. PCA Implementation\n",
    "    print(f\"\\nApplying PCA to '{f_type}' features...\")\n",
    "    scaler_pca = StandardScaler()\n",
    "    X_train_scaled = scaler_pca.fit_transform(X_train_current)\n",
    "    X_test_scaled = scaler_pca.transform(X_test_current)\n",
    "\n",
    "    # Determine n_components for PCA (e.g., explain 95% variance, or fixed number)\n",
    "    # pca_explainer = PCA(random_state=42)\n",
    "    # pca_explainer.fit(X_train_scaled)\n",
    "    # plt.figure()\n",
    "    # plt.plot(np.cumsum(pca_explainer.explained_variance_ratio_))\n",
    "    # plt.xlabel('Number of Components')\n",
    "    # plt.ylabel('Cumulative Explained Variance')\n",
    "    # plt.title(f'PCA Explained Variance for {f_type}')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    # n_pca_components = int(input(f\"Enter n_components for PCA on {f_type} based on plot: \")) # Or set automatically\n",
    "    n_pca_components = 0.95 # Example: Retain 95% of variance\n",
    "\n",
    "    pca_transformer = PCA(n_components=n_pca_components, random_state=42)\n",
    "    X_train_pca_transformed = pca_transformer.fit_transform(X_train_scaled)\n",
    "    X_test_pca_transformed = pca_transformer.transform(X_test_scaled)\n",
    "    print(f\"  Original {f_type} feature dimension: {X_train_scaled.shape[1]}\")\n",
    "    print(f\"  PCA-transformed {f_type} feature dimension: {X_train_pca_transformed.shape[1]}\")\n",
    "\n",
    "    for algo_name, base_model in ml_algorithms_part1.items():\n",
    "        # Re-initialize model to ensure fresh training\n",
    "        current_ml_model = base_model.__class__(**base_model.get_params())\n",
    "        results_part2 = evaluate_and_store_metrics(current_ml_model, X_train_pca_transformed, y_train,\n",
    "                                                 X_test_pca_transformed, y_test,\n",
    "                                                 f_type, \"PCA\", algo_name, results_part2)\n",
    "\n",
    "    # 2. Feature Selection Implementation (e.g., SelectKBest)\n",
    "    print(f\"\\nApplying Feature Selection (SelectKBest) to '{f_type}' features...\")\n",
    "    # Note: Scaling can also be applied before SelectKBest if ML algo is sensitive,\n",
    "    # but f_classif is less dependent on it than PCA. Using X_train_current (unscaled or scaled as per your Part 1).\n",
    "    # If using chi2, ensure features are non-negative. X_train_scaled might have negative values.\n",
    "    # For simplicity, let's use X_train_current. If it contains negative values, f_classif is safer than chi2.\n",
    "    \n",
    "    num_original_feats = X_train_current.shape[1]\n",
    "    if num_original_feats <= 1:\n",
    "        print(f\"  Skipping SelectKBest for {f_type} as it has {num_original_feats} feature(s).\")\n",
    "    else:\n",
    "        # Determine k for SelectKBest (e.g., half the features, or a fixed number like 50/100)\n",
    "        # k_best_features = max(1, min(100, num_original_feats // 2)) # Example\n",
    "        # You might want to tune k using X_val_current\n",
    "        k_best_features = 'all' if num_original_feats < 10 else max(1, num_original_feats // 2) # Adjust k as needed\n",
    "        if k_best_features != 'all' and k_best_features > num_original_feats:\n",
    "             k_best_features = num_original_feats\n",
    "\n",
    "\n",
    "        # Using f_classif as it's generally applicable.\n",
    "        # If your features are strictly non-negative (e.g. histograms), chi2 is also an option.\n",
    "        # Ensure X_train_current is suitable for the score_func (e.g. no negative values for chi2)\n",
    "        # A scaler for feature selection can be added if needed\n",
    "        # scaler_fs = StandardScaler()\n",
    "        # X_train_fs_scaled = scaler_fs.fit_transform(X_train_current)\n",
    "        # X_test_fs_scaled = scaler_fs.transform(X_test_current)\n",
    "\n",
    "        selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "        try:\n",
    "            # Using X_train_current and y_train. If features have negative values and you want to use chi2,\n",
    "            # you'd need to preprocess them (e.g., MinMaxScaler).\n",
    "            X_train_selected_feats = selector.fit_transform(X_train_current, y_train)\n",
    "            X_test_selected_feats = selector.transform(X_test_current)\n",
    "            print(f\"  Original {f_type} feature dimension: {num_original_feats}\")\n",
    "            print(f\"  SelectKBest-transformed {f_type} feature dimension: {X_train_selected_feats.shape[1]}\")\n",
    "\n",
    "            for algo_name, base_model in ml_algorithms_part1.items():\n",
    "                current_ml_model = base_model.__class__(**base_model.get_params())\n",
    "                results_part2 = evaluate_and_store_metrics(current_ml_model, X_train_selected_feats, y_train,\n",
    "                                                         X_test_selected_feats, y_test,\n",
    "                                                         f_type, f\"SelectKBest_k{k_best_features}\", algo_name, results_part2)\n",
    "        except ValueError as e:\n",
    "            print(f\"  Error with SelectKBest for {f_type} (k={k_best_features}): {e}. Check for negative inputs if using chi2, or if k is valid.\")\n",
    "\n",
    "\n",
    "# 3. Comparison of All Results\n",
    "print(\"\\n\\n--- Overall Results Comparison ---\")\n",
    "\n",
    "# Convert Part 1 and Part 2 results to DataFrames for easy viewing\n",
    "results_part1_df = pd.DataFrame.from_dict(results_part1, orient='index')\n",
    "results_part2_df = pd.DataFrame.from_dict(results_part2, orient='index')\n",
    "\n",
    "print(\"\\nResults from Part 1 (Original Features):\")\n",
    "print(results_part1_df)\n",
    "\n",
    "print(\"\\nResults from Part 2 (PCA and Feature Selection):\")\n",
    "print(results_part2_df)\n",
    "\n",
    "# Combine for a comprehensive table\n",
    "all_results_list = []\n",
    "# Part 1\n",
    "for key, metrics in results_part1.items():\n",
    "    parts = key.split('_', 1) # Split only on the first underscore\n",
    "    feature_set = parts[0]\n",
    "    algorithm = parts[1] if len(parts) > 1 else 'N/A'\n",
    "    all_results_list.append({'Feature Set': feature_set, 'Method': 'Original', 'Algorithm': algorithm, **metrics})\n",
    "\n",
    "# Part 2\n",
    "for key, metrics in results_part2.items():\n",
    "    parts = key.split('_', 2) # e.g., \"color_PCA_SVM\" or \"hog_SelectKBest_k50_RF\"\n",
    "    feature_set = parts[0]\n",
    "    method_applied = parts[1]\n",
    "    algorithm = parts[2]\n",
    "    if \"SelectKBest\" in method_applied: # To handle k in the method name if present\n",
    "         method_parts_further = method_applied.split('_') # e.g. SelectKBest_kVal\n",
    "         if len(parts) > 2: # if key was color_SelectKBest_k50_SVM\n",
    "             method_applied = parts[1] # This will be SelectKBest\n",
    "             algorithm = parts[2]\n",
    "         else: # if key was color_SelectKBest_SVM (no k in key from evaluate_and_store_metrics)\n",
    "             algorithm = \"N/A\" # Or adjust parsing based on your exact key format\n",
    "\n",
    "    all_results_list.append({'Feature Set': feature_set, 'Method': method_applied, 'Algorithm': algorithm, **metrics})\n",
    "\n",
    "comparison_df_final = pd.DataFrame(all_results_list)\n",
    "comparison_df_final = comparison_df_final.set_index(['Feature Set', 'Method', 'Algorithm']).sort_index()\n",
    "\n",
    "print(\"\\nComprehensive Comparison Table (Accuracy and F1-Score):\")\n",
    "print(comparison_df_final[['accuracy', 'f1_score']])\n",
    "\n",
    "# --- Add your detailed discussions and interpretations below ---\n",
    "# For each feature type:\n",
    "#   - Compare Original vs. PCA vs. SelectKBest for each ML algorithm.\n",
    "#   - Discuss changes in dimensionality.\n",
    "#   - Impact on performance (accuracy, precision, recall, F1, training time if measured).\n",
    "#   - Why might PCA improve/degrade performance? (decorrelation, noise reduction vs. info loss)\n",
    "#   - Why might Feature Selection improve/degrade performance? (simpler model, reduced overfitting vs. loss of useful info)\n",
    "#   - Compare PCA vs. Feature Selection directly. Which was better and under what conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# pca_temp = PCA().fit(X_train_scaled_for_pca)\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(np.cumsum(pca_temp.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.title(f'PCA Explained Variance for {feature_name}')\n",
    "# plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle=':', alpha=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Applying Feature Selection (SelectKBest) and Evaluating ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Starting Part 2.2: Feature Selection (SelectKBest) ---\n",
      "\n",
      "Skipping SelectKBest for HSV: Training features are empty or mismatched with labels.\n",
      "\n",
      "Skipping SelectKBest for HoG: Training features are empty or mismatched with labels.\n",
      "\n",
      "Skipping SelectKBest for Gabor: Training features are empty or mismatched with labels.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% --- Part 2.2: Applying Feature Selection (SelectKBest) and Evaluating ML Models ---\n",
    "print(\"\\n\\n--- Starting Part 2.2: Feature Selection (SelectKBest) ---\")\n",
    "\n",
    "if PART1_FEATURE_TRAIN_DICT_NAME not in globals() or \\\n",
    "   not isinstance(globals()[PART1_FEATURE_TRAIN_DICT_NAME], dict) or \\\n",
    "   'y_train_final' not in globals() or \\\n",
    "   'ml_models' not in globals(): #\n",
    "    print(f\"Error: Part 1 feature sets (e.g., {PART1_FEATURE_TRAIN_DICT_NAME}), labels (y_train_final), or ml_models are not defined/valid. Please run Part 1 first.\")\n",
    "else:\n",
    "    feature_data_train_source_skb = globals()[PART1_FEATURE_TRAIN_DICT_NAME]\n",
    "    feature_data_val_source_skb = globals()[PART1_FEATURE_VAL_DICT_NAME]\n",
    "    feature_data_test_source_skb = globals()[PART1_FEATURE_TEST_DICT_NAME]\n",
    "    \n",
    "    for feature_name, X_train_orig in feature_data_train_source_skb.items():\n",
    "        X_val_orig = feature_data_val_source_skb.get(feature_name)\n",
    "        X_test_orig = feature_data_test_source_skb.get(feature_name)\n",
    "\n",
    "        current_y_train = y_train_final\n",
    "        current_y_val = y_val_final\n",
    "        current_y_test = y_test_final\n",
    "\n",
    "        if not isinstance(X_train_orig, np.ndarray) or X_train_orig.size == 0 or \\\n",
    "           (X_train_orig.ndim == 2 and X_train_orig.shape[0] != current_y_train.shape[0]) or \\\n",
    "           (X_train_orig.ndim == 1 and X_train_orig.shape[0] == 0 and current_y_train.shape[0] > 0):\n",
    "            print(f\"\\nSkipping SelectKBest for {feature_name}: Training features are empty or mismatched with labels.\")\n",
    "            continue\n",
    "\n",
    "        run_validation_skb = isinstance(X_val_orig, np.ndarray) and X_val_orig.size > 0 and \\\n",
    "                             isinstance(current_y_val, np.ndarray) and current_y_val.size > 0 and \\\n",
    "                             X_val_orig.shape[0] == current_y_val.shape[0]\n",
    "        if not run_validation_skb and isinstance(X_val_orig, np.ndarray) and X_val_orig.size > 0:\n",
    "             print(f\"Warning for SelectKBest {feature_name} validation: Label mismatch or empty labels. Validation eval will be skipped.\")\n",
    "\n",
    "        run_test_skb = isinstance(X_test_orig, np.ndarray) and X_test_orig.size > 0 and \\\n",
    "                       isinstance(current_y_test, np.ndarray) and current_y_test.size > 0 and \\\n",
    "                       X_test_orig.shape[0] == current_y_test.shape[0]\n",
    "        if not run_test_skb and isinstance(X_test_orig, np.ndarray) and X_test_orig.size > 0:\n",
    "            print(f\"Warning for SelectKBest {feature_name} test: Label mismatch or empty labels. Test eval will be skipped.\")\n",
    "            \n",
    "        print(f\"\\n===== Applying Feature Selection (SelectKBest) to {feature_name} Features =====\")\n",
    "        print(f\"Original Train X shape: {X_train_orig.shape}, y shape: {current_y_train.shape}\")\n",
    "\n",
    "        # 1. Scale original features before feature selection\n",
    "        scaler_for_skb = StandardScaler()\n",
    "        X_train_scaled_for_skb = scaler_for_skb.fit_transform(X_train_orig)\n",
    "        X_val_scaled_for_skb = scaler_for_skb.transform(X_val_orig) if run_validation_skb and X_val_orig.ndim == 2 else np.array([])\n",
    "        X_test_scaled_for_skb = scaler_for_skb.transform(X_test_orig) if run_test_skb and X_test_orig.ndim == 2 else np.array([])\n",
    "        \n",
    "        # 2. Apply SelectKBest\n",
    "        original_num_features_skb = X_train_scaled_for_skb.shape[1]\n",
    "        \n",
    "        if original_num_features_skb == 0:\n",
    "            print(f\"No features to select from for {feature_name} after scaling. Skipping SelectKBest.\")\n",
    "            continue\n",
    "\n",
    "        # Determine k: min(100, 50% of features, or original_num_features if very few)\n",
    "        if original_num_features_skb <= 10: \n",
    "            k_final_select_skb = original_num_features_skb\n",
    "        else:\n",
    "            k_half_select_skb = int(original_num_features_skb * 0.5)\n",
    "            k_final_select_skb = min(100, k_half_select_skb) \n",
    "            if k_final_select_skb == 0 and original_num_features_skb > 0 : k_final_select_skb = 1 # Ensure at least 1 feature\n",
    "\n",
    "        print(f\"Selecting top {k_final_select_skb} features from {feature_name} (original scaled: {original_num_features_skb})...\")\n",
    "        \n",
    "        try:\n",
    "            selector_skb = SelectKBest(score_func=f_classif, k=k_final_select_skb)\n",
    "            X_train_selectkbest = selector_skb.fit_transform(X_train_scaled_for_skb, current_y_train)\n",
    "            X_val_selectkbest = selector_skb.transform(X_val_scaled_for_skb) if run_validation_skb and X_val_scaled_for_skb.size > 0 else np.array([])\n",
    "            X_test_selectkbest = selector_skb.transform(X_test_scaled_for_skb) if run_test_skb and X_test_scaled_for_skb.size > 0 else np.array([])\n",
    "        except ValueError as e_skb: \n",
    "             print(f\"  SelectKBest Error for {feature_name}: {e_skb}. Possibly k > n_features. Trying k=min(k_final_select_skb, n_features).\")\n",
    "             try:\n",
    "                 k_fallback_skb_val = min(k_final_select_skb, X_train_scaled_for_skb.shape[1])\n",
    "                 if k_fallback_skb_val == 0 and X_train_scaled_for_skb.shape[1] > 0: k_fallback_skb_val = 1\n",
    "                 elif k_fallback_skb_val == 0:\n",
    "                     print(f\"  Cannot select 0 features for {feature_name} (original has {X_train_scaled_for_skb.shape[1]}). Skipping SelectKBest.\")\n",
    "                     continue\n",
    "                 selector_fallback_skb_inst = SelectKBest(score_func=f_classif, k=k_fallback_skb_val)\n",
    "                 X_train_selectkbest = selector_fallback_skb_inst.fit_transform(X_train_scaled_for_skb, current_y_train)\n",
    "                 X_val_selectkbest = selector_fallback_skb_inst.transform(X_val_scaled_for_skb) if run_validation_skb and X_val_scaled_for_skb.size > 0 else np.array([])\n",
    "                 X_test_selectkbest = selector_fallback_skb_inst.transform(X_test_scaled_for_skb) if run_test_skb and X_test_scaled_for_skb.size > 0 else np.array([])\n",
    "                 k_final_select_skb = k_fallback_skb_val \n",
    "             except Exception as e_fallback_skb_inner:\n",
    "                 print(f\"  SelectKBest Fallback Error for {feature_name}: {e_fallback_skb_inner}. Skipping this feature set for SelectKBest.\")\n",
    "                 continue\n",
    "        \n",
    "        print(f\"Shape after SelectKBest - Train: {X_train_selectkbest.shape}, Val: {X_val_selectkbest.shape if X_val_selectkbest.size > 0 else 'N/A'}, Test: {X_test_selectkbest.shape if X_test_selectkbest.size > 0 else 'N/A'}\")\n",
    "\n",
    "        # 3. Data was already scaled before selection.\n",
    "\n",
    "        # 4. Evaluate ML models on selected features\n",
    "        for model_name, model_instance_orig in ml_models.items(): # Using ml_models from Part 1\n",
    "            print(f\"\\n--- Training {model_name} with SelectKBest {feature_name} ---\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            current_model_skb = type(model_instance_orig)(**model_instance_orig.get_params())\n",
    "            if 'random_state' in current_model_skb.get_params(): current_model_skb.set_params(random_state=42)\n",
    "            if hasattr(current_model_skb, 'n_jobs') and model_name != \"Gaussian Naive Bayes\": current_model_skb.set_params(n_jobs=-1)\n",
    "            \n",
    "            try:\n",
    "                current_model_skb.fit(X_train_selectkbest, current_y_train)\n",
    "                train_time = time.time() - start_time\n",
    "\n",
    "                val_accuracy_skb = 0.0\n",
    "                val_report_dict_skb_default = {'macro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0}, 'accuracy': 0.0}\n",
    "                if run_validation_skb and X_val_selectkbest.size > 0 :\n",
    "                    y_val_pred_skb = current_model_skb.predict(X_val_selectkbest)\n",
    "                    val_accuracy_skb = accuracy_score(current_y_val, y_val_pred_skb)\n",
    "                    labels_val_eval_skb = np.unique(np.concatenate((current_y_val, y_val_pred_skb)))\n",
    "                    target_names_val_eval_skb = [label_mapping.get(l, str(l)) for l in labels_val_eval_skb] if 'label_mapping' in globals() and label_mapping else [str(l) for l in labels_val_eval_skb]\n",
    "                    val_report_dict_skb = classification_report(current_y_val, y_val_pred_skb, target_names=target_names_val_eval_skb, labels=labels_val_eval_skb, output_dict=True, zero_division=0)\n",
    "                    print(f\"Validation Accuracy (SelectKBest): {val_accuracy_skb:.4f}\")\n",
    "                else:\n",
    "                    val_report_dict_skb = val_report_dict_skb_default\n",
    "                    if run_validation_skb: print(f\"Validation evaluation skipped for SelectKBest {feature_name} with {model_name} (empty X_val_selectkbest).\")\n",
    "\n",
    "                test_accuracy_skb = 0.0\n",
    "                test_report_str_skb = \"N/A (Test evaluation skipped)\"\n",
    "                test_report_dict_skb_default = {'macro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0}, 'accuracy': 0.0}\n",
    "                test_time_skb = 0.0\n",
    "                if run_test_skb and X_test_selectkbest.size > 0:\n",
    "                    start_test_time = time.time()\n",
    "                    y_test_pred_skb = current_model_skb.predict(X_test_selectkbest)\n",
    "                    test_time_skb = time.time() - start_test_time\n",
    "                    \n",
    "                    test_accuracy_skb = accuracy_score(current_y_test, y_test_pred_skb)\n",
    "                    labels_test_eval_skb = np.unique(np.concatenate((current_y_test, y_test_pred_skb)))\n",
    "                    target_names_test_eval_skb = [label_mapping.get(l, str(l)) for l in labels_test_eval_skb] if 'label_mapping' in globals() and label_mapping else [str(l) for l in labels_test_eval_skb]\n",
    "\n",
    "                    test_report_str_skb = classification_report(current_y_test, y_test_pred_skb, target_names=target_names_test_eval_skb, labels=labels_test_eval_skb, zero_division=0)\n",
    "                    test_report_dict_skb = classification_report(current_y_test, y_test_pred_skb, target_names=target_names_test_eval_skb, labels=labels_test_eval_skb, output_dict=True, zero_division=0)\n",
    "                    print(f\"Test Accuracy (SelectKBest): {test_accuracy_skb:.4f}\")\n",
    "                    print(\"Test Set Classification Report (SelectKBest):\")\n",
    "                    print(test_report_str_skb)\n",
    "                else:\n",
    "                    test_report_dict_skb = test_report_dict_skb_default\n",
    "                    if run_test_skb: print(f\"Test evaluation skipped for SelectKBest {feature_name} with {model_name} (empty X_test_selectkbest).\")\n",
    "\n",
    "                results_part2_selectkbest.append({\n",
    "                    \"Feature Set\": f\"{feature_name}_SelectKBest_{k_final_select_skb}feat\",\n",
    "                    \"ML Model\": model_name,\n",
    "                    \"Validation Accuracy\": round(val_accuracy_skb, 4),\n",
    "                    \"Test Accuracy\": round(test_accuracy_skb, 4),\n",
    "                    \"Test Precision (macro)\": round(test_report_dict_skb['macro avg']['precision'], 4),\n",
    "                    \"Test Recall (macro)\": round(test_report_dict_skb['macro avg']['recall'], 4),\n",
    "                    \"Test F1-Score (macro)\": round(test_report_dict_skb['macro avg']['f1-score'], 4),\n",
    "                    \"Training Time (s)\": round(train_time, 2),\n",
    "                    \"Test Time (s)\": round(test_time_skb, 2)\n",
    "                })\n",
    "            except ValueError as ve_skb_model:\n",
    "                print(f\"ValueError training/evaluating {model_name} with SelectKBest {feature_name}: {ve_skb_model}\")\n",
    "            except Exception as e_skb_model:\n",
    "                print(f\"General error training/evaluating {model_name} with SelectKBest {feature_name}: {e_skb_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4: Displaying Combined Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Summary of Part 2 PCA Results ---\n",
      "No results to display for Part 2 PCA (results_part2_pca list is empty).\n",
      "\n",
      "\n",
      "--- Summary of Part 2 SelectKBest Results ---\n",
      "No results to display for Part 2 SelectKBest (results_part2_selectkbest list is empty).\n",
      "\n",
      "\n",
      "--- Combined Summary of Results (Part 1 Original, Part 2 PCA, Part 2 SelectKBest) ---\n",
      "  Feature Set             ML Model  Validation Accuracy  Test Accuracy  Test Precision (macro)  Test Recall (macro)  Test F1-Score (macro)  Training Time (s)  Test Time (s) Processing_Type Original_Feature_Set\n",
      "8       Gabor        Random Forest               0.1023         0.0694                  0.0800               0.0700                 0.0722               0.17           0.02        Original                Gabor\n",
      "6       Gabor  Logistic Regression               0.0341         0.0417                  0.0146               0.0694                 0.0194               0.06           0.00        Original                Gabor\n",
      "7       Gabor  SVM (Linear Kernel)               0.0341         0.0417                  0.0036               0.0625                 0.0067               0.06           0.00        Original                Gabor\n",
      "0         HSV  Logistic Regression               0.0455         0.0278                  0.0233               0.0333                 0.0274              13.34           0.00        Original                  HSV\n",
      "2         HSV        Random Forest               0.0114         0.0278                  0.0233               0.0200                 0.0214               0.18           0.03        Original                  HSV\n",
      "1         HSV  SVM (Linear Kernel)               0.0227         0.0139                  0.0133               0.0100                 0.0114               0.14           0.00        Original                  HSV\n",
      "4         HoG  SVM (Linear Kernel)               0.0227         0.0556                  0.0486               0.0556                 0.0475               2.11           0.09        Original                  HoG\n",
      "5         HoG        Random Forest               0.0227         0.0417                  0.0503               0.0300                 0.0293               0.36           0.04        Original                  HoG\n",
      "3         HoG  Logistic Regression               0.0114         0.0278                  0.0417               0.0312                 0.0347              66.41           0.00        Original                  HoG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% --- Part 2: Displaying Combined Results ---\n",
    "print(\"\\n\\n--- Summary of Part 2 PCA Results ---\")\n",
    "df_results_part2_pca = pd.DataFrame(results_part2_pca)\n",
    "if not df_results_part2_pca.empty:\n",
    "    print(df_results_part2_pca.sort_values(by=\"Test Accuracy\", ascending=False).to_string())\n",
    "else:\n",
    "    print(\"No results to display for Part 2 PCA (results_part2_pca list is empty).\")\n",
    "\n",
    "print(\"\\n\\n--- Summary of Part 2 SelectKBest Results ---\")\n",
    "df_results_part2_selectkbest = pd.DataFrame(results_part2_selectkbest)\n",
    "if not df_results_part2_selectkbest.empty:\n",
    "    print(df_results_part2_selectkbest.sort_values(by=\"Test Accuracy\", ascending=False).to_string())\n",
    "else:\n",
    "    print(\"No results to display for Part 2 SelectKBest (results_part2_selectkbest list is empty).\")\n",
    "\n",
    "# For a combined comparison, you can concatenate with Part 1 results\n",
    "# Assuming results_part1_optimized is the LIST of DICTS from your updated Part 1\n",
    "# Or df_results_part1_optimized is the DATAFRAME from Part 1\n",
    "\n",
    "df_part1_for_concat_final = pd.DataFrame() # Initialize an empty DataFrame\n",
    "\n",
    "if 'df_results_part1_optimized' in globals() and isinstance(globals()['df_results_part1_optimized'], pd.DataFrame):\n",
    "    df_part1_for_concat_final = globals()['df_results_part1_optimized'].copy()\n",
    "    df_part1_for_concat_final[\"Processing_Type\"] = \"Original\" # Add a type column\n",
    "elif 'results_part1_optimized' in globals() and isinstance(globals()['results_part1_optimized'], list):\n",
    "    df_part1_for_concat_final = pd.DataFrame(globals()['results_part1_optimized'])\n",
    "    if not df_part1_for_concat_final.empty:\n",
    "         df_part1_for_concat_final[\"Processing_Type\"] = \"Original\"\n",
    "else:\n",
    "    print(\"Warning: Part 1 results (results_part1_optimized list or df_results_part1_optimized DataFrame) not found for combined display.\")\n",
    "\n",
    "# Prepare Part 2 DataFrames for concatenation by adding a distinguishing column or modifying \"Feature Set\"\n",
    "df_results_part2_pca_display = df_results_part2_pca.copy()\n",
    "if not df_results_part2_pca_display.empty:\n",
    "    df_results_part2_pca_display[\"Processing_Type\"] = \"PCA\"\n",
    "\n",
    "df_results_part2_skb_display = df_results_part2_selectkbest.copy()\n",
    "if not df_results_part2_skb_display.empty:\n",
    "    df_results_part2_skb_display[\"Processing_Type\"] = \"SelectKBest\"\n",
    "\n",
    "\n",
    "all_results_dfs_final_combined = []\n",
    "if not df_part1_for_concat_final.empty:\n",
    "    all_results_dfs_final_combined.append(df_part1_for_concat_final)\n",
    "if not df_results_part2_pca_display.empty:\n",
    "    all_results_dfs_final_combined.append(df_results_part2_pca_display)\n",
    "if not df_results_part2_skb_display.empty:\n",
    "    all_results_dfs_final_combined.append(df_results_part2_skb_display)\n",
    "\n",
    "if all_results_dfs_final_combined:\n",
    "    df_combined_all_parts = pd.concat(all_results_dfs_final_combined, ignore_index=True)\n",
    "    print(\"\\n\\n--- Combined Summary of Results (Part 1 Original, Part 2 PCA, Part 2 SelectKBest) ---\")\n",
    "    # Sort by Feature Set (original name) and then by Test Accuracy for easier comparison\n",
    "    # We might need to extract original feature name from the modified \"Feature Set\" column\n",
    "    if \"Feature Set\" in df_combined_all_parts.columns:\n",
    "        df_combined_all_parts[\"Original_Feature_Set\"] = df_combined_all_parts[\"Feature Set\"].apply(lambda x: x.split('_')[0] if isinstance(x,str) else \"Unknown\")\n",
    "        print(df_combined_all_parts.sort_values(by=[\"Original_Feature_Set\", \"Test Accuracy\"], ascending=[True, False]).to_string())\n",
    "    else:\n",
    "        print(df_combined_all_parts.sort_values(by=[\"Test Accuracy\"], ascending=[False]).to_string()) # Fallback sort\n",
    "\n",
    "else:\n",
    "    print(\"No results from any part to combine for the final display.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Part 2: Comments and Interpretations\n",
    "#\n",
    "# * **PCA Application:**\n",
    "#     * For each feature set (HSV, HoG, Gabor), how many principal components were selected to retain 95% variance? Does this number make sense given the original dimensionality and nature of the features? (e.g., \"HoG had an original dimensionality of X, and PCA reduced it to Y components, indicating significant redundancy or correlation in the original HoG features.\")\n",
    "#     * How did classification performance with PCA-transformed features compare to using the original scaled features (from Part 1)? Did PCA improve, degrade, or have a mixed effect on accuracy/F1-score for different ML models? (e.g., \"For SVM, PCA on HSV features improved accuracy by Z%, but for Random Forest, it decreased slightly.\")\n",
    "#     * Discuss any significant changes in training/testing times when using PCA. (e.g., \"Training time for all models was notably faster with PCA-transformed features due to the lower dimensionality.\")\n",
    "# * **Feature Selection (SelectKBest with f_classif):**\n",
    "#     * For each feature set, how many features were selected (k)? How does this compare to the original and PCA dimensions?\n",
    "#     * How did performance with the selected features compare to the original scaled features and the PCA-transformed features? (e.g., \"SelectKBest on Gabor features, while reducing features by half, maintained comparable accuracy to the original Gabor set and outperformed PCA for the Logistic Regression model.\")\n",
    "#     * Discuss any significant changes in training/testing times when using feature selection.\n",
    "# * **Overall Comparison:**\n",
    "#     * Which approach (original, PCA, or feature selection) yielded the best balance of performance and efficiency (training/test time) for each feature type and each ML algorithm?\n",
    "#     * Were there any feature types that benefited more from PCA or feature selection than others? Why might this be? (e.g., \"Color-based features (HSV) might have seen less improvement from PCA if color channels were already relatively independent, whereas texture features like Gabor might have more correlated components that PCA could effectively reduce.\")\n",
    "#     * Based on your results, what can you conclude about the utility of PCA and feature selection for this specific image classification task using these traditional features? Are they always beneficial? When might one be preferred over the other?\n",
    "#\n",
    "# *(Please fill in your detailed comments and interpretations here based on the results you obtain.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_combined_all_parts_final DataFrame not found or is empty.\n"
     ]
    }
   ],
   "source": [
    "if 'df_combined_all_parts_final' in globals() and not df_combined_all_parts.empty:\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    # Use 'Original_Feature_Set_Name' for grouping by HSV, HoG, Gabor\n",
    "    # Use 'Processing_Type' for hue\n",
    "    sns.barplot(x=\"ML Model\", y=\"Test Accuracy\", hue=\"Processing_Type\", \n",
    "                data=df_combined_all_parts, palette=\"muted\",\n",
    "                # Optional: use facet grid if you want separate plots per Original_Feature_Set_Name\n",
    "                # col=\"Original_Feature_Set_Name\" \n",
    "               )\n",
    "    plt.title(\"Overall Model Test Accuracy: Original vs PCA vs SelectKBest\", fontsize=18)\n",
    "    plt.ylabel(\"Test Accuracy\", fontsize=14)\n",
    "    plt.xlabel(\"Machine Learning Model\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.legend(title=\"Processing Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"df_combined_all_parts_final DataFrame not found or is empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
